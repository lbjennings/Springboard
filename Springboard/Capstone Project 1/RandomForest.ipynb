{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#package for loop load time bar\n",
    "from tqdm import tqdm\n",
    "#statistical and machine learning packages\n",
    "import scipy as sp\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#import scoring for machine learning\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve,roc_auc_score, auc,precision_recall_curve,classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "\n",
    "#imports for preparing data for sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn. preprocessing import LabelEncoder\n",
    "\n",
    "# packages for plotting \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#command to have graphs display in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2398795</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473747</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2254736</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>431534</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
       "0   2539329        1    prior             1          2                  8   \n",
       "1   2398795        1    prior             2          3                  7   \n",
       "2    473747        1    prior             3          3                 12   \n",
       "3   2254736        1    prior             4          4                  7   \n",
       "4    431534        1    prior             5          4                 15   \n",
       "\n",
       "   days_since_prior_order  \n",
       "0                     NaN  \n",
       "1                    15.0  \n",
       "2                    21.0  \n",
       "3                    29.0  \n",
       "4                    28.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading user order information\n",
    "instacart_file=pd.read_csv('/Users/luca/anaconda2/Springboard/Capstone Project 1/Data/orders.csv')\n",
    "df_orders=pd.DataFrame(instacart_file,)\n",
    "df_orders.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                  3421083\n",
       "user_id                    206209\n",
       "eval_set                        3\n",
       "order_number                  100\n",
       "order_dow                       7\n",
       "order_hour_of_day              24\n",
       "days_since_prior_order         31\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#capture the last order information for each user\n",
    "g = df_orders.groupby('user_id')\n",
    "data_p1=g.last()\n",
    "data_p1['order_from_last']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#capture the second to last order information for each user\n",
    "data_p2=g.nth(-2)\n",
    "data_p2['order_from_last']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#capture the third to last order information for each user\n",
    "data_p3=g.nth(-3)\n",
    "data_p3['order_from_last']=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#capture the fourth to last order information for each user\n",
    "data_p4=g.nth(-4)\n",
    "data_p4['order_from_last']=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an effort to save computation time, we will work first with a much smaller portion of the data. At the end of the notebook we will attempt to use as much as our system will allow.\n",
    "\n",
    "## Concern: \n",
    "An issue with data wrangling is deciding how to preserve the time component of order history of the customer. I originally sought to segregate the data by breaking it into chunks by order: the test data is the customer's 2nd previous order, the training data the customer’s the 3rd and 4th previous orders together then splitting on it to cross validate. I then test on the 2nd to previous order as the test set. This was taking way to much time to run. I've adjust to a small test run below. The training data is only a small portion 150 cutomer orders from the 3rd previous order they made. The test set is the customers 2nd previous order. ( The most current previous order did not have lavels for all customers, hence, I choose to move to the customers 2nd previous order).\n",
    "\n",
    "I feel like this should work on a much larger set. This data come from a kaggle competition so I feel like I shouldn't have to reduce as much as I am. Thoughts on how I'm approaching the data set up wrong? Insights in how to reduce run time to maximize data usage? \n",
    "\n",
    "# The small set test drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>33120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28985</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9327</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>45918</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>30035</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  product_id  add_to_cart_order  reordered\n",
       "0         2       33120                  1          1\n",
       "1         2       28985                  2          1\n",
       "2         2        9327                  3          0\n",
       "3         2       45918                  4          1\n",
       "4         2       30035                  5          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#capture the third to last order information for each user\n",
    "data_p3=data_p3.reset_index()\n",
    "\n",
    "#loading product reorder information\n",
    "instacart_file2=pd.read_csv('/Users/luca/anaconda2/Springboard/Capstone Project 1/Data/order_products__prior.csv')\n",
    "df_prod_orders=pd.DataFrame(instacart_file2,)\n",
    "df_prod_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Chocolate Sandwich Cookies</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>All-Seasons Salt</td>\n",
       "      <td>104</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Robust Golden Unsweetened Oolong Tea</td>\n",
       "      <td>94</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Smart Ones Classic Favorites Mini Rigatoni Wit...</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Green Chile Anytime Sauce</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                       product_name  aisle_id  \\\n",
       "0           1                         Chocolate Sandwich Cookies        61   \n",
       "1           2                                   All-Seasons Salt       104   \n",
       "2           3               Robust Golden Unsweetened Oolong Tea        94   \n",
       "3           4  Smart Ones Classic Favorites Mini Rigatoni Wit...        38   \n",
       "4           5                          Green Chile Anytime Sauce         5   \n",
       "\n",
       "   department_id  \n",
       "0             19  \n",
       "1             13  \n",
       "2              7  \n",
       "3              1  \n",
       "4             13  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading information for product names\n",
    "instacart_products=pd.read_csv('/Users/luca/anaconda2/Springboard/Capstone Project 1/Data/products.csv')\n",
    "df_prod=pd.DataFrame(instacart_products,)\n",
    "df_prod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>user_id</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_from_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>34050</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>142903</td>\n",
       "      <td>30.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>46802</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>142903</td>\n",
       "      <td>30.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>9755</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>174840</td>\n",
       "      <td>13.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>25466</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>174840</td>\n",
       "      <td>13.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>45437</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>174840</td>\n",
       "      <td>13.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  product_id  add_to_cart_order  reordered  user_id  \\\n",
       "0         7       34050                  1          0   142903   \n",
       "1         7       46802                  2          0   142903   \n",
       "2        16        9755                  1          1   174840   \n",
       "3        16       25466                  2          0   174840   \n",
       "4        16       45437                  3          0   174840   \n",
       "\n",
       "   days_since_prior_order eval_set  order_dow  order_hour_of_day  \\\n",
       "0                    30.0    prior          2                 14   \n",
       "1                    30.0    prior          2                 14   \n",
       "2                    13.0    prior          3                 12   \n",
       "3                    13.0    prior          3                 12   \n",
       "4                    13.0    prior          3                 12   \n",
       "\n",
       "   order_number  order_from_last  \n",
       "0            11                3  \n",
       "1            11                3  \n",
       "2            18                3  \n",
       "3            18                3  \n",
       "4            18                3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add reorder information to training data\n",
    "df_train=pd.merge(df_prod_orders,data_p3, how= 'inner',left_on=\"order_id\", right_on='order_id')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                  False\n",
       "product_id                False\n",
       "add_to_cart_order         False\n",
       "reordered                 False\n",
       "user_id                   False\n",
       "days_since_prior_order    False\n",
       "eval_set                  False\n",
       "order_dow                 False\n",
       "order_hour_of_day         False\n",
       "order_number              False\n",
       "order_from_last           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to make sure NaN is taken care of \n",
    "df_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                  206209\n",
       "product_id                 42505\n",
       "add_to_cart_order            100\n",
       "reordered                      2\n",
       "user_id                   206209\n",
       "days_since_prior_order        31\n",
       "eval_set                       1\n",
       "order_dow                      7\n",
       "order_hour_of_day             24\n",
       "order_number                  97\n",
       "order_from_last                1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see how many products and users we have \n",
    "df_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                  550\n",
       "product_id                472\n",
       "add_to_cart_order          34\n",
       "reordered                   2\n",
       "user_id                   550\n",
       "days_since_prior_order     31\n",
       "eval_set                    1\n",
       "order_dow                   7\n",
       "order_hour_of_day          24\n",
       "order_number               63\n",
       "order_from_last             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 150 customers to make predictions for \n",
    "small_train=df_train.sample(550)\n",
    "small_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>user_id</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_from_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3128</td>\n",
       "      <td>4605</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>197075</td>\n",
       "      <td>14.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3128</td>\n",
       "      <td>24184</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>197075</td>\n",
       "      <td>14.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3128</td>\n",
       "      <td>22395</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>197075</td>\n",
       "      <td>14.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3128</td>\n",
       "      <td>5115</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>197075</td>\n",
       "      <td>14.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3128</td>\n",
       "      <td>884</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>197075</td>\n",
       "      <td>14.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  product_id  add_to_cart_order  reordered  user_id  \\\n",
       "0      3128        4605                  1          1   197075   \n",
       "1      3128       24184                  2          1   197075   \n",
       "2      3128       22395                  3          1   197075   \n",
       "3      3128        5115                  4          1   197075   \n",
       "4      3128         884                  5          0   197075   \n",
       "\n",
       "   days_since_prior_order eval_set  order_dow  order_hour_of_day  \\\n",
       "0                    14.0    prior          0                  9   \n",
       "1                    14.0    prior          0                  9   \n",
       "2                    14.0    prior          0                  9   \n",
       "3                    14.0    prior          0                  9   \n",
       "4                    14.0    prior          0                  9   \n",
       "\n",
       "   order_number  order_from_last  \n",
       "0            25                2  \n",
       "1            25                2  \n",
       "2            25                2  \n",
       "3            25                2  \n",
       "4            25                2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data frame to ensure we have the same users in the test set\n",
    "sample=pd.DataFrame(small_train['user_id'])\n",
    "\n",
    "#capture the second to last order information for each user as a test set\n",
    "data_p2=g.nth(-2)\n",
    "data_p2['order_from_last']=2\n",
    "data_p2=data_p2.reset_index()\n",
    "\n",
    "#for test set add in reorder information\n",
    "df_test=pd.merge(df_prod_orders,data_p2, how= 'inner',left_on=\"order_id\", right_on='order_id')\n",
    "\n",
    "#since we have train and test data broken apart by user previous order we can ensure we test only the users we trained for\n",
    "small_test=pd.merge(df_test,sample, how= 'inner',left_on=\"user_id\", right_on='user_id')\n",
    "small_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                   550\n",
       "product_id                3812\n",
       "add_to_cart_order           49\n",
       "reordered                    2\n",
       "user_id                    550\n",
       "days_since_prior_order      31\n",
       "eval_set                     1\n",
       "order_dow                    7\n",
       "order_hour_of_day           22\n",
       "order_number                63\n",
       "order_from_last              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#small_test=df_test.sample(150)\n",
    "small_test.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we prep the feature columns to be in an appropriate format to utilize sklearn api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>user_id</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_from_last</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1660380</th>\n",
       "      <td>2685103</td>\n",
       "      <td>46949</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>192899</td>\n",
       "      <td>12.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224393</th>\n",
       "      <td>365945</td>\n",
       "      <td>21560</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>196158</td>\n",
       "      <td>15.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111037</th>\n",
       "      <td>181484</td>\n",
       "      <td>32700</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>203778</td>\n",
       "      <td>27.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59517</th>\n",
       "      <td>97572</td>\n",
       "      <td>42768</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>97646</td>\n",
       "      <td>8.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570102</th>\n",
       "      <td>926950</td>\n",
       "      <td>46346</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>190497</td>\n",
       "      <td>18.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id  product_id  add_to_cart_order  reordered  user_id  \\\n",
       "1660380   2685103       46949                  9          1   192899   \n",
       "224393     365945       21560                 18          1   196158   \n",
       "111037     181484       32700                  8          0   203778   \n",
       "59517       97572       42768                  2          0    97646   \n",
       "570102     926950       46346                  9          0   190497   \n",
       "\n",
       "         days_since_prior_order eval_set  order_dow  order_hour_of_day  \\\n",
       "1660380                    12.0    prior          5                 22   \n",
       "224393                     15.0    prior          0                  8   \n",
       "111037                     27.0    prior          2                 22   \n",
       "59517                       8.0    prior          1                 20   \n",
       "570102                     18.0    prior          6                  6   \n",
       "\n",
       "         order_number  order_from_last  day_0  day_1  day_2  day_3  day_4  \\\n",
       "1660380            11                3      0      0      0      0      0   \n",
       "224393             21                3      1      0      0      0      0   \n",
       "111037              2                3      0      0      1      0      0   \n",
       "59517               3                3      0      1      0      0      0   \n",
       "570102             12                3      0      0      0      0      0   \n",
       "\n",
       "         day_5  day_6  \n",
       "1660380      1      0  \n",
       "224393       0      0  \n",
       "111037       0      0  \n",
       "59517        0      0  \n",
       "570102       0      1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use pandas one hot encoder on training data's order_dow with added 'day' to column name\n",
    "df_dow=pd.get_dummies(small_train['order_dow'],prefix='day')\n",
    "#add reorder information to training data\n",
    "train=pd.merge(small_train,df_dow, how= 'inner',left_index= True, right_index=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>user_id</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_from_last</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3128</td>\n",
       "      <td>4605</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>197075</td>\n",
       "      <td>14.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3128</td>\n",
       "      <td>24184</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>197075</td>\n",
       "      <td>14.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3128</td>\n",
       "      <td>22395</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>197075</td>\n",
       "      <td>14.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3128</td>\n",
       "      <td>5115</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>197075</td>\n",
       "      <td>14.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3128</td>\n",
       "      <td>884</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>197075</td>\n",
       "      <td>14.0</td>\n",
       "      <td>prior</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  product_id  add_to_cart_order  reordered  user_id  \\\n",
       "0      3128        4605                  1          1   197075   \n",
       "1      3128       24184                  2          1   197075   \n",
       "2      3128       22395                  3          1   197075   \n",
       "3      3128        5115                  4          1   197075   \n",
       "4      3128         884                  5          0   197075   \n",
       "\n",
       "   days_since_prior_order eval_set  order_dow  order_hour_of_day  \\\n",
       "0                    14.0    prior          0                  9   \n",
       "1                    14.0    prior          0                  9   \n",
       "2                    14.0    prior          0                  9   \n",
       "3                    14.0    prior          0                  9   \n",
       "4                    14.0    prior          0                  9   \n",
       "\n",
       "   order_number  order_from_last  day_0  day_1  day_2  day_3  day_4  day_5  \\\n",
       "0            25                2      1      0      0      0      0      0   \n",
       "1            25                2      1      0      0      0      0      0   \n",
       "2            25                2      1      0      0      0      0      0   \n",
       "3            25                2      1      0      0      0      0      0   \n",
       "4            25                2      1      0      0      0      0      0   \n",
       "\n",
       "   day_6  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use pandas one hot encoder on test data's order_dow with added 'day' to column name \n",
    "df_dow=pd.get_dummies(small_test['order_dow'],prefix='day')\n",
    "#add reorder information to training data\n",
    "test=pd.merge(small_test,df_dow, how= 'inner',left_index= True, right_index=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#capture feature names and make a list\n",
    "features=train[['add_to_cart_order', 'days_since_prior_order', 'order_dow','order_hour_of_day', 'order_number', 'order_from_last', 'day_0','day_1', 'day_2', 'day_3', 'day_4', 'day_5', 'day_6']]\n",
    "feature_list = list(features.columns)\n",
    "features=features.columns\n",
    "\n",
    "\n",
    "#make a training set for sklearn features\n",
    "xtrain = train[features]\n",
    "\n",
    "#make a test set for sklearn features\n",
    "xtest = test[features]\n",
    "\n",
    "#convert target column into array for training set\n",
    "ytrain = pd.factorize(small_train['reordered'])[0]\n",
    "\n",
    "#convert target column into array for test set \n",
    "ytest = pd.factorize(small_test['reordered'])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% reorders in training set 0.470909\n",
      "% reorders in test set 0.404326\n"
     ]
    }
   ],
   "source": [
    "#see if the training data has the proper balance of reorders \n",
    "print ('% reorders in training set {:2f}'.format(float(ytrain.sum())/ytrain.size))\n",
    "print ('% reorders in test set {:2f}'.format(float(ytest.sum())/ytest.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "Should I be concerned about the difference here in imbalance here? The EDA of all the data showed that reorders occured at 60% overall. Here in the training set, which is all the 3rd previous orders for customers the reorder rate  and the test set are also different. \n",
    "\n",
    "# Question:\n",
    "What is to long for a runtime? This one, the randomized grid search, takes a few hours in the full set I would like to run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we use svm with rbf kernel on the data to make predictions for reorders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.96\n",
      "Accuracy on test data: 0.62\n",
      "F1 Score on train data: 0.9597\n",
      "F1 Score on validation (train-test set) data: 0.4599\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.78      0.71      4489\n",
      "          1       0.55      0.40      0.46      3047\n",
      "\n",
      "avg / total       0.61      0.62      0.61      7536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#to tune parameters \n",
    "clf=svm.SVC(kernel='rbf')\n",
    "\n",
    "#fit classifier to validation set\n",
    "clf.fit( xtrain , ytrain )\n",
    "\n",
    "#get the prediction set for the validation \n",
    "preds_train_svm = clf.predict( xtrain )\n",
    "\n",
    "#make some predictions\n",
    "preds_svm = clf.predict( xtest )\n",
    "\n",
    "\n",
    "#print the accuracy score for the training data\n",
    "training_accuracy = clf.score( xtrain , ytrain )\n",
    "print(\"Accuracy on training data: {:0.2f}\".format( training_accuracy ) )\n",
    "\n",
    "#print the accuracy score for the test data\n",
    "test_accuracy = clf.score(xtest , ytest)\n",
    "print(\"Accuracy on test data: {:0.2f}\".format( test_accuracy ) )\n",
    "\n",
    "#print training f1 score\n",
    "fscore_train = metrics.f1_score( ytrain , preds_train_svm )\n",
    "print(\"F1 Score on train data: {:0.4f}\".format(fscore_train))\n",
    "\n",
    "#print testing f1 score\n",
    "fscore = metrics.f1_score( ytest , preds_svm , pos_label=1 )\n",
    "print(\"F1 Score on validation (train-test set) data: {:0.4f}\".format( fscore ) )\n",
    "\n",
    "print (classification_report( ytest , preds_svm ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # I should tune parametes here. Definitely overfitting\n",
    "   \n",
    "   SVM does not have predict_proba module. We can instead plot the distance from the decision line.\n",
    "   Can plot a histogram od the decision function. Need to work on making plot of the decision function on the plane. \n",
    "   See if I can plot the support vectors as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49688 entries, 0 to 49687\n",
      "Data columns (total 4 columns):\n",
      "product_id       49688 non-null int64\n",
      "product_name     49688 non-null object\n",
      "aisle_id         49688 non-null int64\n",
      "department_id    49688 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_prod.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3504,  985],\n",
       "       [1843, 1204]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at confusion matrix\n",
    "confusion_matrix( ytest , preds_svm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  125.,   598.,  1180.,  2653.,  1175.,   696.,   499.,   336.,\n",
       "          219.,    55.]),\n",
       " array([-1.11598277, -0.87321556, -0.63044835, -0.38768114, -0.14491393,\n",
       "         0.09785328,  0.34062049,  0.58338771,  0.82615492,  1.06892213,\n",
       "         1.31168934]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAEDJJREFUeJzt3VuMnGd9x/Hvr04IUkGNg52w+BAH\n6h7CRU20MlFzQ5uSOBGKQ9tIyQVxUZBBSiqQuMDARRAoKpEKSJFoJAMWjkQTUg6Ki6ymxlBFXATs\noDSJcVMvgcTrMwQFJKqUmH8v9nUz2HuYXe/O2Pt8P9Jo3vm/z8z7PDu7/nme9zCpKiRJ7fm9YXdA\nkjQcBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpURcMuwPTWbZsWa1Zs2bY3ZCk\n88oTTzzxs6paPlO7czoA1qxZw969e4fdDUk6ryR5vp92TgFJUqMMAElqlAEgSY0yACSpUQaAJDXK\nAJCkRhkAktQoA0CSGmUASFKjDADNi5GVq0ky8NvIytXDHrp03jqnLwWh88fRQwe5/CPfGvh2n7/3\nXQPfprRY+AlAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNWrGAEiyKsl3k+xPsi/JB7v6J5IcSvJk\nd7ux5zkfTTKW5Nkk1/fUN3S1sSRbFmZIkqR+9HMewCvAh6vqh0leDzyRZFe37nNV9Y+9jZNcCdwK\nvBV4E/DtJH/Urf488E5gHNiTZEdV/Wg+BiJJmp0ZA6CqjgBHuuVfJdkPrJjmKRuBh6rqZeAnScaA\n9d26sap6DiDJQ11bA0CShmBW+wCSrAHeBny/K92V5Kkk25Is7WorgIM9TxvvalPVJUlD0HcAJHkd\n8HXgQ1X1S+B+4C3AOiY+IXzmVNNJnl7T1E/fzuYke5PsPXHiRL/dkyTNUl8BkORCJv7x/0pVfQOg\nqo5V1cmq+i3wBV6d5hkHVvU8fSVweJr676iqrVU1WlWjy5cvn+14JEl96ucooABfAvZX1Wd76iM9\nzd4NPNMt7wBuTXJRkiuAtcAPgD3A2iRXJHkNEzuKd8zPMCRJs9XPUUDXAO8Bnk7yZFf7GHBbknVM\nTOP8FHg/QFXtS/IwEzt3XwHurKqTAEnuAh4FlgDbqmrfPI5FkjQL/RwF9D0mn7/fOc1z7gHumaS+\nc7rnSZIGxzOBJalRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCk\nRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqU\nASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqNmDIAkq5J8N8n+JPuSfLCrX5JkV5ID3f3S\nrp4k9yUZS/JUkqt6XmtT1/5Akk0LNyxJ0kz6+QTwCvDhqvpT4GrgziRXAluA3VW1FtjdPQa4AVjb\n3TYD98NEYAB3A28H1gN3nwoNSdLgzRgAVXWkqn7YLf8K2A+sADYC27tm24Gbu+WNwAM14XHg4iQj\nwPXArqp6sap+AewCNszraCRJfZvVPoAka4C3Ad8HLquqIzAREsClXbMVwMGep413tanqkqQh6DsA\nkrwO+Drwoar65XRNJ6nVNPXTt7M5yd4ke0+cONFv9yRJs9RXACS5kIl//L9SVd/oyse6qR26++Nd\nfRxY1fP0lcDhaeq/o6q2VtVoVY0uX758NmORJM1CP0cBBfgSsL+qPtuzagdw6kieTcAjPfXbu6OB\nrgZe6qaIHgWuS7K02/l7XVeTJA3BBX20uQZ4D/B0kie72seATwMPJ7kDeAG4pVu3E7gRGAN+DbwX\noKpeTPIpYE/X7pNV9eK8jEKSNGszBkBVfY/J5+8Brp2kfQF3TvFa24Bts+mgJGlheCawJDXKAJCk\nRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqU\nASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkA\nktQoA0CSGmUASFKjDABJatSMAZBkW5LjSZ7pqX0iyaEkT3a3G3vWfTTJWJJnk1zfU9/Q1caSbJn/\noUiSZqOfTwBfBjZMUv9cVa3rbjsBklwJ3Aq8tXvOPyVZkmQJ8HngBuBK4LaurSRpSC6YqUFVPZZk\nTZ+vtxF4qKpeBn6SZAxY360bq6rnAJI81LX90ax7LEmaF2ezD+CuJE91U0RLu9oK4GBPm/GuNlVd\nkjQkcw2A+4G3AOuAI8BnunomaVvT1M+QZHOSvUn2njhxYo7dkyTNZE4BUFXHqupkVf0W+AKvTvOM\nA6t6mq4EDk9Tn+y1t1bVaFWNLl++fC7dkyT1YU4BkGSk5+G7gVNHCO0Abk1yUZIrgLXAD4A9wNok\nVyR5DRM7infMvduSpLM1407gJA8C7wCWJRkH7gbekWQdE9M4PwXeD1BV+5I8zMTO3VeAO6vqZPc6\ndwGPAkuAbVW1b95HI0nqWz9HAd02SflL07S/B7hnkvpOYOeseidJWjCeCSxJjTIAJKlRBoAkNcoA\nkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJ\napQBIEmNMgAkqVEGgCQ1ygCQpEbN+KXwOr+MrFzN0UMHh92NwVlyIUmGsuk3rljFkfEXhrJtaT4Y\nAIvM0UMHufwj3xr4dp+/910D3yYAJ38zlPHCEMcszROngCSpUQaAJDXKAJCkRhkAktQoA0CSGmUA\nSFKjDABJapQBIEmNmjEAkmxLcjzJMz21S5LsSnKgu1/a1ZPkviRjSZ5KclXPczZ17Q8k2bQww5Ek\n9aufTwBfBjacVtsC7K6qtcDu7jHADcDa7rYZuB8mAgO4G3g7sB64+1RoSJKGY8YAqKrHgBdPK28E\ntnfL24Gbe+oP1ITHgYuTjADXA7uq6sWq+gWwizNDRZI0QHPdB3BZVR0B6O4v7eorgN4rkY13tanq\nkqQhme+dwJNdlrGmqZ/5AsnmJHuT7D1x4sS8dk6S9Kq5BsCxbmqH7v54Vx8HVvW0WwkcnqZ+hqra\nWlWjVTW6fPnyOXZPkjSTuQbADuDUkTybgEd66rd3RwNdDbzUTRE9ClyXZGm38/e6riZJGpIZvw8g\nyYPAO4BlScaZOJrn08DDSe4AXgBu6ZrvBG4ExoBfA+8FqKoXk3wK2NO1+2RVnb5jWZI0QDMGQFXd\nNsWqaydpW8CdU7zONmDbrHonSVowngksSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJ\napQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRM34lpKQpLLmQ\nJAPf7BtXrOLI+AsD364WHwNAmquTv+Hyj3xr4Jt9/t53DXybWpycApKkRhkAktQoA0CSGmUASFKj\nDABJapQBIEmN8jDQBTCycjVHDx0cdjckaVoGwAI4eujgUI4PB48Rl9Q/p4AkqVEGgCQ16qwCIMlP\nkzyd5Mkke7vaJUl2JTnQ3S/t6klyX5KxJE8luWo+BiBJmpv5+ATwF1W1rqpGu8dbgN1VtRbY3T0G\nuAFY2902A/fPw7YlSXO0EFNAG4Ht3fJ24Oae+gM14XHg4iQjC7B9SVIfzjYACvj3JE8k2dzVLquq\nIwDd/aVdfQXQe2zkeFeTJA3B2R4Gek1VHU5yKbAryX9N03ayC6fXGY0mgmQzwOrVq8+ye9IiNKTv\nIQC/i2CxOasAqKrD3f3xJN8E1gPHkoxU1ZFuiud413wcWNXz9JXA4UlecyuwFWB0dPSMgJCaN6Tv\nIQDPM1ls5jwFlOT3k7z+1DJwHfAMsAPY1DXbBDzSLe8Abu+OBroaeOnUVJEkafDO5hPAZcA3u4+i\nFwD/XFX/lmQP8HCSO4AXgFu69juBG4Ex4NfAe89i25KkszTnAKiq54A/m6T+c+DaSeoF3DnX7UmS\n5pdnAktSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIa5XcCS+rfkC5E50XoFoYBIKl/\nQ7oQnRehWxhOAUlSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CjPA5B07hvSCWiwuE9CMwAk\nnfuGdAIaLO6T0JwCkqRGGQCS1CgDQJIaZQBIUqMMAElq1KI+Cmhk5WqOHjo47G5I0jlpUQfA0UMH\nvXa5JE3BKSBJapQBIEmNMgAkqVEGgCQ1auABkGRDkmeTjCXZMujtS9KsdBeiG/RtZOXqBR/aQI8C\nSrIE+DzwTmAc2JNkR1X9aJD9kKS+DelCdIM4mnDQnwDWA2NV9VxV/S/wELBxwH2QJDH4AFgB9J6Z\nNd7VJEkDlqoa3MaSW4Drq+p93eP3AOur6u972mwGNncP/xh4dmAdfNUy4GdD2O65wLG3p9Vxw+Id\n++VVtXymRoM+E3gcWNXzeCVwuLdBVW0Ftg6yU6dLsreqRofZh2Fx7O2NvdVxQ9tjh8FPAe0B1ia5\nIslrgFuBHQPugySJAX8CqKpXktwFPAosAbZV1b5B9kGSNGHgF4Orqp3AzkFvd5aGOgU1ZI69Pa2O\nG9oe+2B3AkuSzh1eCkKSGmUAMHF4apJ9SX6bZMojAhbjZSySXJJkV5ID3f3SKdqdTPJkdztvd9zP\n9B4muSjJV7v130+yZvC9XBh9jP3vkpzoeZ/fN4x+zrck25IcT/LMFOuT5L7u5/JUkqsG3cdhMQAm\nPAP8NfDYVA16LmNxA3AlcFuSKwfTvQW1BdhdVWuB3d3jyfxPVa3rbjcNrnvzp8/38A7gF1X1h8Dn\ngHsH28uFMYvf36/2vM9fHGgnF86XgQ3TrL8BWNvdNgP3D6BP5wQDAKiq/VU10wlni/UyFhuB7d3y\nduDmIfZlofXzHvb+PL4GXJskA+zjQlmsv78zqqrHgBenabIReKAmPA5cnGRkML0bLgOgf4v1MhaX\nVdURgO7+0inavTbJ3iSPJzlfQ6Kf9/D/21TVK8BLwBsG0ruF1e/v79900yBfS7JqkvWL0WL9257R\nov5O4F5Jvg28cZJVH6+qR/p5iUlq58UhVNONfRYvs7qqDid5M/CdJE9X1Y/np4cD0897eN6+zzPo\nZ1z/CjxYVS8n+QATn4T+csF7NnyL9T2fUTMBUFV/dZYvMeNlLM5V0409ybEkI1V1pPvYe3yK1zjc\n3T+X5D+AtwHnWwD08x6eajOe5ALgD5h++uB80c9lWH7e8/ALLJL9H304b/+2z5ZTQP1brJex2AFs\n6pY3AWd8GkqyNMlF3fIy4BrgfPwOh37ew96fx98C36nFcbLMjGM/bd77JmD/APs3TDuA27ujga4G\nXjo1LbroVVXzN+DdTPwv4GXgGPBoV38TsLOn3Y3AfzPxP9+PD7vf8zT2NzBx9M+B7v6Srj4KfLFb\n/nPgaeA/u/s7ht3vsxjvGe8h8Engpm75tcC/AGPAD4A3D7vPAxz7PwD7uvf5u8CfDLvP8zTuB4Ej\nwG+6v/M7gA8AH+jWh4kjpH7c/X6PDrvPg7p5JrAkNcopIElqlAEgSY0yACSpUQaAJDXKAJCkRhkA\nktQoA0CSGmUASFKj/g925S5BwlH5wgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106104c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#can look at decision line \n",
    "clf.decision_function(xtest)\n",
    "\n",
    "#plot the histogram of distance from boundry\n",
    "plt.hist(clf.decision_function(xtest),edgecolor='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now look at model measurements: ROC Curve, Precision-Recall Curves and AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ecfecd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#predict the probabilities for each observation in training set\n",
    "#pred_train_prob_svm = clf.decision_function(xtrain)[:,1]\n",
    "\n",
    "#predict the probabilities for each observation in test set\n",
    "#pred_prob_svm = clf.predict_proba(xtest)[:,1]\n",
    "\n",
    "#get false positive rate, true positive rate, and thresholds for training data\n",
    "xfpr , xtpr , xthres = roc_curve(ytrain , clf.decision_function(xtrain) )\n",
    "\n",
    "#get false positive rate, true positive rate, and thresholds for test data\n",
    "fpr , tpr , thres = roc_curve( ytest , clf.decision_function(xtest))\n",
    "\n",
    "#plot base line at .5 probability\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "#plot model train and test\n",
    "plt.plot(fpr,tpr,label='testing data')\n",
    "plt.plot(xfpr,xtpr, 'g-',label='training data')\n",
    "#add labels\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ecfe1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xprec_score,xrecall_score,xthresholds=precision_recall_curve( ytrain , clf.decision_function(xtrain) )\n",
    "\n",
    "prec_score,recall_score,thresholds=precision_recall_curve( ytest , clf.decision_function(xtest))\n",
    "\n",
    "plt.plot([1,0],[0,1],'k--')\n",
    "plt.plot(recall_score,prec_score,label='testing data')\n",
    "plt.plot(xrecall_score,xprec_score,'g-',label='training data')\n",
    "#plt.plot(xfpr,xtpr, 'g-',label='training data')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61944516965695895"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(ytest , clf.decision_function(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.58279009  0.61041114  0.56399204  0.6127321   0.60750507]\n"
     ]
    }
   ],
   "source": [
    "cv_auc_scores=cross_val_score(clf, xtrain , ytrain, cv=5, scoring='roc_auc')\n",
    "print(cv_auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The above was with default settings lets tune the model and see if we can imporve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/luca/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#know lets tune the parameters for the svm \n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Sklearn recommends for an initial search, a logarithmic grid with basis 10 is often helpful. Using a basis \n",
    "# of 2, a finer tuning can be achieved but at a much higher cost.\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "#param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "\n",
    "parameters = {'C': C_range , 'gamma' : gamma_range }\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "#grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "            \n",
    "\n",
    "#randomize grid search for parameters with cross validation and refit on entire training set\n",
    "#spread across two jobs and seed a random state\n",
    "rs = RandomizedSearchCV(clf,  param_distributions= parameters ,cv= cv, refit= True, n_jobs= 2, random_state= 42, scoring='f1')\n",
    "\n",
    "#fit grid search on random forest over grid\n",
    "rs.fit( xtrain ,  ytrain )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question:\n",
    "Does my approach at cross-validation voilate any principles? Do you see anything wrong here? Can I do it better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save best parameters to use on test set\n",
    "best_c = rs.best_params_['C'] \n",
    "best_gamma=rs.best_params_['gamma'] \n",
    "\n",
    "#print best parameter results\n",
    "print(\"the best regulization C is {} and the best gamma, radius of influence of support vectors is {}\".format(best_c,best_gamma))\n",
    "print(\"the best f1 score with these is {}\".format(rs.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to tune parameters \n",
    "clf=svm.SVC( kernel='rbf', C= best_c , gamma= best_gamma )\n",
    "\n",
    "#fit classifier to validation set\n",
    "clf.fit( xtrain , ytrain )\n",
    "\n",
    "#get the prediction set for the validation \n",
    "preds_train_svm = clf.predict( xtrain )\n",
    "\n",
    "#make some predictions\n",
    "preds_svm = clf.predict( xtest )\n",
    "\n",
    "\n",
    "#print the accuracy score for the training data\n",
    "training_accuracy = clf.score( xtrain , ytrain )\n",
    "print(\"Accuracy on training data: {:0.2f}\".format( training_accuracy ) )\n",
    "\n",
    "#print the accuracy score for the test data\n",
    "test_accuracy = clf.score(xtest , ytest)\n",
    "print(\"Accuracy on test data: {:0.2f}\".format( test_accuracy ) )\n",
    "\n",
    "#print training f1 score\n",
    "fscore_train = metrics.f1_score( ytrain , preds_train_svm )\n",
    "print(\"F1 Score on train data: {:0.4f}\".format(fscore_train))\n",
    "\n",
    "#print testing f1 score\n",
    "fscore = metrics.f1_score( ytest , preds_svm , pos_label=1 )\n",
    "print(\"F1 Score on validation (train-test set) data: {:0.4f}\".format( fscore ) )\n",
    "\n",
    "print (classification_report( ytest , preds_svm ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can look at decision line \n",
    "clf.decision_function(xtest)\n",
    "\n",
    "#plot the histogram of distance from boundry\n",
    "plt.hist(clf.decision_function(xtest),edgecolor='k' )\n",
    "#add labels\n",
    "plt.xlabel(\"Distance from Boundry Line\")\n",
    "plt.ylabel(\"Samples\")\n",
    "plt.title('SVM Decision Funciton Histogram')\n",
    "plt.legend(loc=3)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#plot ROC curve \n",
    "#get false positive rate, true positive rate, and thresholds for training data\n",
    "xfpr , xtpr , xthres = roc_curve(ytrain , clf.decision_function(xtrain) )\n",
    "\n",
    "#get false positive rate, true positive rate, and thresholds for test data\n",
    "fpr , tpr , thres = roc_curve( ytest , clf.decision_function(xtest) )\n",
    "\n",
    "#plot base line at .5 probability\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "#plot model train and test\n",
    "plt.plot(fpr,tpr,label='testing data')\n",
    "plt.plot(xfpr,xtpr, 'g-',label='training data')\n",
    "#add labels\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "#plot the precision-recall curve for tuned model\n",
    "#get values for training set\n",
    "xprec_score,xrecall_score,xthresholds=precision_recall_curve( ytrain , clf.decision_function(xtrain) )\n",
    "#get values for test set\n",
    "prec_score,recall_score,thresholds=precision_recall_curve( ytest , clf.decision_function(xtest))\n",
    "\n",
    "#plot lines\n",
    "plt.plot([1,0],[0,1],'k--')\n",
    "plt.plot(recall_score,prec_score,label='testing data')\n",
    "plt.plot(xrecall_score,xprec_score,'g-',label='training data')\n",
    "#add labels\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=3)\n",
    "plt.show()\n",
    "         \n",
    "print( 'roc_auc_score',roc_auc_score(ytest , clf.decision_function(xtest))  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements to make later: add one hot encode to hod column, scale/normalize all features, cross validate the auc scores, plot decision boundry on plane, add feature engineering...\n",
    "\n",
    "# Next Random Forest \n",
    "the mini version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#know lets tune the parameters for the random forest\n",
    "\n",
    "#set parametets to tune in Random Grid Search (# trees in forest and # of features per tree)\n",
    "parameters={'n_estimators':range(20,40),'max_features':['auto',1,2,3,4,5]}\n",
    "\n",
    "#create an instance of the random forest classifier\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "#randomize grid search for parameters with cross validation and refit on entire training set\n",
    "#spread across two jobs and seed a random state\n",
    "rs = RandomizedSearchCV(rf, param_distributions=parameters,cv=5,refit=True,n_jobs=2,random_state=42,scoring='f1')\n",
    "\n",
    "#fit grid search on random forest over grid\n",
    "rs.fit( xtrain ,  ytrain )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "How do you pick the appropriate range for # of trees? The best # of trees was at the top range of trees. I’m thinking the model will always want the top number (its overfitting).  Should I also tune the gini purity or the minimum leaf node parameter? What all do you recommend to tune in the random forest? \n",
    "\n",
    "Model is overfitting on training data (.86 compared to .61). Could look at tuning the gini-index (or leaf node min).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save best parameters to use on test set\n",
    "best_n = rs.best_params_['n_estimators'] \n",
    "best_features=rs.best_params_['max_features'] \n",
    "\n",
    "#print best parameter results\n",
    "print(\"the best number of trees is {} with a maximum number of features of {}\".format(best_n,best_features))\n",
    "print(\"the best f1 score with these is {}\".format(rs.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create classifier from best parameters out of grid search\n",
    "clf=rs.best_estimator_\n",
    "#fit classifier to validation set\n",
    "clf.fit(xtrain,ytrain)\n",
    "\n",
    "#get the prediction set for the validation \n",
    "preds_train_rf = clf.predict(xtrain)\n",
    "\n",
    "#make some predictions\n",
    "preds_rf = clf.predict(xtest)\n",
    "\n",
    "\n",
    "#print the accuracy score for the training data\n",
    "training_accuracy = clf.score( xtrain , ytrain )\n",
    "print(\"Accuracy on training data: {:0.2f}\".format( training_accuracy ) )\n",
    "\n",
    "#print the accuracy score for the test data\n",
    "test_accuracy = clf.score(xtest , ytest)\n",
    "print(\"Accuracy on test data: {:0.2f}\".format( test_accuracy ) )\n",
    "\n",
    "#print training f1 score\n",
    "fscore_train = metrics.f1_score( ytrain , preds_train_rf )\n",
    "print(\"F1 Score on train data: {:0.4f}\".format(fscore_train))\n",
    "\n",
    "#print testing f1 score\n",
    "fscore = metrics.f1_score( ytest , preds_rf , pos_label=1 )\n",
    "print(\"F1 Score on validation (train-test set) data: {:0.4f}\".format( fscore ) )\n",
    "\n",
    "\n",
    "print ( classification_report ( ytest , preds_rf ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at confusion matrix\n",
    "confusion_matrix( ytest , preds_rf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Capture model feature importance \n",
    "importances=clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the variable importances\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');\n",
    "plt.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the probabilities for each observation in training set\n",
    "pred_train_prob_rf = clf.predict_proba(xtrain)[:,1]\n",
    "\n",
    "#predict the probabilities for each observation in test set\n",
    "pred_prob_rf = clf.predict_proba(xtest)[:,1]\n",
    "\n",
    "#get false positive rate, true positive rate, and thresholds for training data\n",
    "xfpr , xtpr , xthres = roc_curve(ytrain , pred_train_prob_rf )\n",
    "\n",
    "#get false positive rate, true positive rate, and thresholds for test data\n",
    "fpr , tpr , thres = roc_curve( ytest , pred_prob_rf )\n",
    "\n",
    "#plot base line at .5 probability\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "#plot model train and test\n",
    "plt.plot(fpr,tpr,label='testing data')\n",
    "plt.plot(xfpr,xtpr, 'g-',label='training data')\n",
    "#add labels\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xprec_score,xrecall_score,xthresholds=precision_recall_curve( ytrain , pred_train_prob_rf )\n",
    "\n",
    "prec_score,recall_score,thresholds=precision_recall_curve( ytest , pred_prob_rf)\n",
    "\n",
    "plt.plot([1,0],[0,1],'k--')\n",
    "plt.plot(recall_score,prec_score,label='testing data')\n",
    "plt.plot(xrecall_score,xprec_score,'g-',label='training data')\n",
    "#plt.plot(xfpr,xtpr, 'g-',label='training data')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(ytest , pred_prob_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validate on scoring of auc (20 min to run) \n",
    "cv_auc_scores=cross_val_score(clf, xtrain , ytrain , cv=5, scoring='roc_auc')\n",
    "print(cv_auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concern:\n",
    "The Kaggle competition best f1 score was around .409. I have my output slightly different. How can I be doing so much better with such little feature engineering? I feel like I must be doing something wrong here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ignore below. Mostly larger sets that was taking to much computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concern:\n",
    "\n",
    "I've been trying to make a good decision on how to handle the data. If I want to one hot encode all the product_ids then I need to reduce the customer base for memory limit uses. My reason for thinking this is to compare the against the single vector decomposition I started with. I'm thinking now, I should disregard that line of evaluation and build on this random forest with better feature columns. I would then have to adjust the SVM to be similiar.\n",
    "\n",
    "Another issue with data wrangling is deciding how to preserve the time component of order history of the customer. I originally sought to segregate the data by breaking it into chunks by order: the test data the last order the validation set the customer's 2nd previous order, and the training data the customer's 3rd previous order (you see that above). Below you see my final decision, lumping the 3rd and 4th previous orders together into the training set, spliting on it to cross validate. Then testing on the 2nd to previous order as the test set. (The last order for each customer did not all contain labels to test against, hence I choose to move a step further down the customer's order history timeline.) \n",
    " \n",
    "This is one reason my data wrangling paper has been delayed. I've been trying to decide how to set up the RF, and SVM to handle it. \n",
    "\n",
    "## Question:\n",
    "\n",
    "Does my approach at cross-validation voilate any principles? Do you see anything wrong here? Can I do it better?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#set the training data to just the 4th and 3rd previous orders\n",
    "data_set_train=pd.concat([data_p3,data_p4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#reset index \n",
    "data_set_train=data_set.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#add reorder information to training data\n",
    "df_train=pd.merge(df_prod_orders,data_set_train, how= 'inner',left_on=\"order_id\", right_on='order_id')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# fill in Nan with zero\n",
    "df_train=df_train.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#check to make sure NaN is taken care of \n",
    "df_train.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is now in the format wrangling is complete. We shall set up the data for use in sklearn. We will need to choose the features to consider and separate the labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#capture feature names and make a list\n",
    "features=df_train[['add_to_cart_order','days_since_prior_order','order_dow','order_from_last','order_hour_of_day','order_number']]\n",
    "feature_list = list(features.columns)\n",
    "features=features.columns\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#convert target column into array for training set\n",
    "ytrain = pd.factorize(df_train['reordered'])[0]\n",
    "ytrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#create test set and add reorder information \n",
    "df_test=pd.merge(df_prod_orders,data_p2, how= 'inner',left_on=\"order_id\", right_on='order_id')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#convert target column into array for test set \n",
    "ytest = pd.factorize(df_test['reordered'])[0]\n",
    "ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#see if the training data has the proper balance of reorders \n",
    "print ('% reorders in training set {:2f}'.format(float(ytrain.sum())/ytrain.size))\n",
    "print ('% reorders in test set {:2f}'.format(float(ytest.sum())/ytest.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "Should I be concerned about the difference here in imbalance here? The EDA of all the data showed that reorders occured at 60% overall. Here in the training set, which is all the 3rd and 4th previous orders for customers the reorder rate is around 50% and the test set close to 40%. \n",
    "\n",
    "Below the grid search that bit to run. What is to long for a runtime? This one takes a few hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#make a training set for sklearn features\n",
    "xtrain = df_train[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#make a test set for sklearn features\n",
    "xtest = df_test[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the data set up for sklearn lets do some machine learning. First will shall tune the parameters of the random forest classifier. Using the best parameters from cross validation, retrain the model on the training data and predict on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#know lets tune the parameters for the random forest\n",
    "\n",
    "#set parametets to tune in Random Grid Search (# trees in forest and # of features per tree)\n",
    "parameters={'n_estimators':range(20,40),'max_features':['auto',1,2,3,4,5]}\n",
    "\n",
    "#create an instance of the random forest classifier\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "#randomize grid search for parameters with cross validation and refit on entire training set\n",
    "#spread across two jobs and seed a random state\n",
    "rs = RandomizedSearchCV(rf, param_distributions=parameters,cv=5,refit=True,n_jobs=2,random_state=42,scoring='f1')\n",
    "\n",
    "#fit grid search on random forest over grid\n",
    "rs.fit( xtrain ,  ytrain )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: \n",
    "What is to long for a runtime? This one, the randomized grid search, takes a few hours.\n",
    "How do you pick the appropriate range for # of trees? The best # of trees was at the top range of trees. I’m thinking the model will always want the top number (its overfitting).  I understand the range how to pick the range of max_features. Should I also tune the gini purity or the minimum leaf node parameter? What all do you recommend to tune in the random forest? \n",
    "\n",
    "## Concern:\n",
    "Need to expand range on number of trees since best result was at the boundry of test ranges. (Will it always take the max here? Is it overfitting? )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#save best parameters to use on test set\n",
    "best_n = rs.best_params_['n_estimators'] \n",
    "best_features=rs.best_params_['max_features'] \n",
    "\n",
    "#print best parameter results\n",
    "print(\"the best number of trees is {} with a maximum number of features of {}\".format(best_n,best_features))\n",
    "print(\"the best f1 score with these is {}\".format(rs.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters are tuned. We have 29 trees in the forest each using 4 out of the 6 features to learn. (need to expand in future). Next we will retrain on the training data with these parameters and predict on the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#create classifier from best parameters out of grid search\n",
    "clf=rs.best_estimator_\n",
    "#fit classifier to validation set\n",
    "clf.fit(xtrain,ytrain)\n",
    "\n",
    "#get the prediction set for the validation \n",
    "preds_train_rf = clf.predict(xtrain)\n",
    "\n",
    "#make some predictions\n",
    "preds_rf = clf.predict(xtest)\n",
    "\n",
    "\n",
    "#print the accuracy score for the training data\n",
    "training_accuracy = clf.score( xtrain , ytrain )\n",
    "print(\"Accuracy on training data: {:0.2f}\".format( training_accuracy ) )\n",
    "\n",
    "#print the accuracy score for the test data\n",
    "test_accuracy = clf.score(xtest , ytest)\n",
    "print(\"Accuracy on test data: {:0.2f}\".format( test_accuracy ) )\n",
    "\n",
    "#print training f1 score\n",
    "fscore_train = metrics.f1_score( ytrain , preds_train_rf )\n",
    "print(\"F1 Score on train data: {:0.4f}\".format(fscore_train))\n",
    "\n",
    "#print testing f1 score\n",
    "fscore = metrics.f1_score( ytest , preds_rf , pos_label=1 )\n",
    "print(\"F1 Score on validation (train-test set) data: {:0.4f}\".format( fscore ) )\n",
    "\n",
    "\n",
    "print ( classification_report ( ytest , preds_rf ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concern:\n",
    "The Kaggle competition best score was around .409. I have my output slightly different. How can I be doing so much better with such little feature engineering?\n",
    "\n",
    "Model is overfitting on training data (.86 compared to .61). Could look at tuning the gini-index (or leaf node min). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#look at confusion matrix\n",
    "confusion_matrix( ytest , preds_rf )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next lets take a look at which features the model used for prediciton the most. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#make a list of feature and feature importance\n",
    "list(zip(df_train[features], clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Capture model feature importance \n",
    "importances=clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#plot the variable importances\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');\n",
    "plt.tight_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at the ROC and evaluations of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#predict the probabilities for each observation in training set\n",
    "pred_train_prob_rf = clf.predict_proba(xtrain)[:,1]\n",
    "\n",
    "#predict the probabilities for each observation in test set\n",
    "pred_prob_rf = clf.predict_proba(xtest)[:,1]\n",
    "\n",
    "#get false positive rate, true positive rate, and thresholds for training data\n",
    "xfpr , xtpr , xthres = roc_curve(ytrain , pred_train_prob_rf )\n",
    "\n",
    "#get false positive rate, true positive rate, and thresholds for test data\n",
    "fpr , tpr , thres = roc_curve( ytest , pred_prob_rf )\n",
    "\n",
    "#plot base line at .5 probability\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "#plot model train and test\n",
    "plt.plot(fpr,tpr,label='testing data')\n",
    "plt.plot(xfpr,xtpr, 'g-',label='training data')\n",
    "#add labels\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "xprec_score,xrecall_score,xthresholds=precision_recall_curve( ytrain , pred_train_prob_rf )\n",
    "\n",
    "prec_score,recall_score,thresholds=precision_recall_curve( ytest , pred_prob_rf)\n",
    "\n",
    "plt.plot([1,0],[0,1],'k--')\n",
    "plt.plot(recall_score,prec_score,label='testing data')\n",
    "plt.plot(xrecall_score,xprec_score,'g-',label='training data')\n",
    "#plt.plot(xfpr,xtpr, 'g-',label='training data')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "roc_auc_score(ytest , pred_prob_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# cross validate on scoring of auc (20 min to run) \n",
    "cv_auc_scores=cross_val_score(clf, xtrain , ytrain , cv=5, scoring='roc_auc')\n",
    "print(cv_auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  # Now lets loow at the SVM model\n",
    "  \n",
    "  ## Question:\n",
    "  \n",
    "  Should a do a mask on the train test set?\n",
    "  \n",
    "  Come back and scale the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_2d = scaler.fit_transform(X_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "rbf: \\exp(-\\gamma \\|x-x'\\|^2). \\gamma is specified by keyword gamma, must be greater than 0.\n",
    "\n",
    "\n",
    "When training an SVM with the Radial Basis Function (RBF) kernel, two parameters must be considered: C and gamma. The parameter C, common to all SVM kernels, trades off misclassification of training examples against simplicity of the decision surface. A low C makes the decision surface smooth, while a high C aims at classifying all training examples correctly. gamma defines how much influence a single training example has. The larger gamma is, the closer other examples must be to be affected.\n",
    "Proper choice of C and gamma is critical to the SVM’s performance. One is advised to use sklearn.model_selection.GridSearchCV with C and gamma spaced exponentially far apart to choose good values.\n",
    "\n",
    "If gamma is too large, the radius of the area of influence of the support vectors only includes the support vector itself and no amount of regularization with C will be able to prevent overfitting.When gamma is very small, the model is too constrained and cannot capture the complexity or “shape” of the data. The region of influence of any selected support vector would include the whole training set. The resulting model will behave similarly to a linear model with a set of hyperplanes that separate the centers of high density of any pair of two classes.\n",
    "\n",
    "Smooth models (lower gamma values) can be made more complex by selecting a larger number of support vectors (larger C values) hence the diagonal of good performing models.\n",
    "\n",
    "The radius of the RBF kernel alone acts as a good structural regularizer. In practice though it might still be interesting to limit the number of support vectors with a lower value of C so as to favor models that use less memory and that are faster to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#know lets tune the parameters for the random forest\n",
    "\n",
    "#set parametets to tune in Random Grid Search (# trees in forest and # of features per tree)\n",
    "parameters={'n_estimators':range(1,30),'max_features':['auto',1,2,3,4,5]}\n",
    "\n",
    "#create an instance of the random forest classifier\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "#randomize grid search for parameters with cross validation and refit on entire training set\n",
    "#spread across two jobs and seed a random state\n",
    "rs = RandomizedSearchCV(rf, param_distributions=parameters,cv=5,refit=True,n_jobs=2,random_state=42,scoring='f1')\n",
    "\n",
    "#fit grid search on random forest over grid\n",
    "rs.fit(xtrain_rf,ytrain_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "\n",
    "#to tune parameters \n",
    "clf=svm.SVC(kernel='rbf')\n",
    "\n",
    "#fit classifier to validation set\n",
    "clf.fit( xtrain , ytrain )\n",
    "\n",
    "#get the prediction set for the validation \n",
    "preds_train_svm = clf.predict( xtrain )\n",
    "\n",
    "#make some predictions\n",
    "preds_svm = clf.predict( xtest )\n",
    "\n",
    "\n",
    "#print the accuracy score for the training data\n",
    "training_accuracy = clf.score( xtrain , ytrain )\n",
    "print(\"Accuracy on training data: {:0.2f}\".format( training_accuracy ) )\n",
    "\n",
    "#print the accuracy score for the test data\n",
    "test_accuracy = clf.score(xtest , ytest)\n",
    "print(\"Accuracy on test data: {:0.2f}\".format( test_accuracy ) )\n",
    "\n",
    "#print training f1 score\n",
    "fscore_train = metrics.f1_score( ytrain , preds_train_svm )\n",
    "print(\"F1 Score on train data: {:0.4f}\".format(fscore_train))\n",
    "\n",
    "#print testing f1 score\n",
    "fscore = metrics.f1_score( ytest , preds_svm , pos_label=1 )\n",
    "print(\"F1 Score on validation (train-test set) data: {:0.4f}\".format( fscore ) )\n",
    "\n",
    "print (classification_report( ytest , preds_svm ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "\n",
    "#create classifier from best parameters out of grid search\n",
    "#clf=rs.best_estimator_\n",
    "\n",
    "clf=svm.SVC(kernel='rbf')\n",
    "\n",
    "#fit classifier to validation set\n",
    "clf.fit( xtrain , ytrain )\n",
    "\n",
    "#get the prediction set for the validation \n",
    "preds_train_svm = clf.predict( xtrain )\n",
    "\n",
    "#make some predictions\n",
    "preds_svm = clf.predict( xtest )\n",
    "\n",
    "\n",
    "#print the accuracy score for the training data\n",
    "training_accuracy = clf.score( xtrain , ytrain )\n",
    "print(\"Accuracy on training data: {:0.2f}\".format( training_accuracy ) )\n",
    "\n",
    "#print the accuracy score for the test data\n",
    "test_accuracy = clf.score(xtest , ytest)\n",
    "print(\"Accuracy on test data: {:0.2f}\".format( test_accuracy ) )\n",
    "\n",
    "#print training f1 score\n",
    "fscore_train = metrics.f1_score( ytrain , preds_train_svm )\n",
    "print(\"F1 Score on train data: {:0.4f}\".format(fscore_train))\n",
    "\n",
    "#print testing f1 score\n",
    "fscore = metrics.f1_score( ytest , preds_svm , pos_label=1 )\n",
    "print(\"F1 Score on validation (train-test set) data: {:0.4f}\".format( fscore ) )\n",
    "\n",
    "print (classification_report( ytest , preds_svm ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# should i do a pipeline\n",
    "\n",
    "#setup steps for pipeline\n",
    "steps=[('SVM',clf)] #add scale function\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "pipeline.fit( xtrain , ytrain )\n",
    "\n",
    "preds_svm = pipeline.predict( xtest )\n",
    "\n",
    "print (classification_report( ytest , preds_svm ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#look at confusion matrix\n",
    "confusion_matrix( ytest , preds_svm )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#make a list of feature and feature importance\n",
    "list(zip(df_train[features], clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Capture model feature importance \n",
    "importances=clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#plot the variable importances\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');\n",
    "plt.tight_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#predict the probabilities for each observation in training set\n",
    "pred_train_prob_svm = clf.predict_proba(xtrain)[:,1]\n",
    "\n",
    "#predict the probabilities for each observation in test set\n",
    "pred_prob_svm = clf.predict_proba(xtest)[:,1]\n",
    "\n",
    "#get false positive rate, true positive rate, and thresholds for training data\n",
    "xfpr , xtpr , xthres = roc_curve(y train , pred_train_prob_svm )\n",
    "\n",
    "#get false positive rate, true positive rate, and thresholds for test data\n",
    "fpr , tpr , thres = roc_curve( ytest , pred_prob_svm )\n",
    "\n",
    "#plot base line at .5 probability\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "#plot model train and test\n",
    "plt.plot(fpr,tpr,label='testing data')\n",
    "plt.plot(xfpr,xtpr, 'g-',label='training data')\n",
    "#add labels\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "xprec_score,xrecall_score,xthresholds=precision_recall_curve( ytrain , pred_train_prob_svm )\n",
    "\n",
    "prec_score,recall_score,thresholds=precision_recall_curve( ytest , pred_prob_svm)\n",
    "\n",
    "plt.plot([1,0],[0,1],'k--')\n",
    "plt.plot(recall_score,prec_score,label='testing data')\n",
    "plt.plot(xrecall_score,xprec_score,'g-',label='training data')\n",
    "#plt.plot(xfpr,xtpr, 'g-',label='training data')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "roc_auc_score(ytest , pred_prob_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "cv_auc_scores=cross_val_score(clf, xtrain , ytrain, cv=5, scoring='roc_auc')\n",
    "print(cv_auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Train classifiers\n",
    "# notes from sklearn\n",
    "# For an initial search, a logarithmic grid with basis\n",
    "# 10 is often helpful. Using a basis of 2, a finer\n",
    "# tuning can be achieved but at a much higher cost.\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# can ignore stuff below. \n",
    "working on the how to split data differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### below is spliting data in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### below if I need to reduce the data size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "rf_small_train=df_rf_train.sample(750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "rf_small_table=rf_small_train.pivot(index='user_id', columns='product_id', values='reordered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_small_table=rf_small_table.replace(0, 1, regex=True)\n",
    "rf_small_table=rf_small_table.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_small_train=rf_small_train.set_index('user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_small_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_small_sample=pd.merge(rf_small_train,rf_small_table, how= 'inner',left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_small_sample.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_small_sample['reordered'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small_features=rf_small_sample.drop(['reordered','eval_set'],axis=1)\n",
    "sm_feature_list = list(small_features.columns)\n",
    "sm_features=small_features.columns\n",
    "len(sm_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small_features['order_id'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#convert target column into array\n",
    "target= pd.factorize(rf_small_sample['reordered'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small_features.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.fit(small_features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small_features.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small_features=small_features.reset_index()\n",
    "small_users=pd.DataFrame(small_features['user_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small_users.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small_products=pd.DataFrame(small_features['product_id'])\n",
    "small_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## work on test data for predict\n",
    "should i just do a train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to one hotencode here for predict to be the same as model features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_small_sample=pd.merge(df_rf_test,small_users, how= 'inner',on='user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_small_sample=pd.merge(rf_small_sample,small_products, how= 'inner',on='product_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_small_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_small_sample.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_small_sample=rf_small_sample.reset_index('user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_small_sample.product_id.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_small_sample.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_small_table=rf_small_sample.pivot(index='user_id',columns='product_id', values='reordered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_small_table=test_small_table.replace(0, 1, regex=True)\n",
    "test_small_table=rf_small_table.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_small_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#rf_small_train=rf_small_train.set_index('user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#join one hot encode back with other features\n",
    "df_rf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get data from test set on user_ids\n",
    "#small_test=df_rf_test.merge(small_users, how='inner', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sm_test_features=small_test.drop(['reordered','eval_set'],axis=1)\n",
    "sm_test_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small_test[small_test['user_id']==71]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sm_preds=clf.predict(sm_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.predict_proba(df_rf_test[features])[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#make a table of the predictions vs. the actual reorders\n",
    "pd.crosstab(df_rf_test['reordered'], preds, rownames=['Actual reorder'], colnames=['Predicted reorder'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#make a list of feature and feature importance\n",
    "list(zip(df_rf_train[features], clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importances=clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#plot the variable importances\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');\n",
    "plt.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
