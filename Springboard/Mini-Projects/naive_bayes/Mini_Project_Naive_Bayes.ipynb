{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Text Classification with Naive Bayes\n",
    "***\n",
    "In the mini-project, you'll learn the basics of text analysis using a subset of movie reviews from the rotten tomatoes database. You'll also use a fundamental technique in Bayesian inference, called Naive Bayes. This mini-project is based on [Lab 10 of Harvard's CS109](https://github.com/cs109/2015lab10) class.  Please free to go to the original lab for additional exercises and solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from six.moves import range\n",
    "\n",
    "# Setup Pandas\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "# Setup Seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [Rotten Tomatoes Dataset](#Rotten-Tomatoes-Dataset)\n",
    "    * [Explore](#Explore)\n",
    "* [The Vector Space Model and a Search Engine](#The-Vector-Space-Model-and-a-Search-Engine)\n",
    "    * [In Code](#In-Code)\n",
    "* [Naive Bayes](#Naive-Bayes)\n",
    "    * [Multinomial Naive Bayes and Other Likelihood Functions](#Multinomial-Naive-Bayes-and-Other-Likelihood-Functions)\n",
    "    * [Picking Hyperparameters for Naive Bayes and Text Maintenance](#Picking-Hyperparameters-for-Naive-Bayes-and-Text-Maintenance)\n",
    "* [Interpretation](#Interpretation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotten Tomatoes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh    imdb     publication                                              quote review_date  rtid      title\n",
       "1         Derek Adams  fresh  114709        Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story\n",
       "2     Richard Corliss  fresh  114709   TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story\n",
       "3         David Ansen  fresh  114709        Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story\n",
       "4       Leonard Klady  fresh  114709         Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story\n",
       "5  Jonathan Rosenbaum  fresh  114709  Chicago Reader  An entertaining computer-generated, hyperreali...  2008-03-10  9559  Toy story"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critics = pd.read_csv('/Users/luca/anaconda2/Springboard/data/critics.csv')\n",
    "#let's drop rows with missing quotes\n",
    "critics = critics[~critics.quote.isnull()]\n",
    "critics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 15561\n",
      "Number of critics: 623\n",
      "Number of movies:  1921\n"
     ]
    }
   ],
   "source": [
    "n_reviews = len(critics)\n",
    "n_movies = critics.rtid.unique().size\n",
    "n_critics = critics.critic.unique().size\n",
    "\n",
    "\n",
    "print(\"Number of reviews: {:d}\".format(n_reviews))\n",
    "print(\"Number of critics: {:d}\".format(n_critics))\n",
    "print(\"Number of movies:  {:d}\".format(n_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEVCAYAAAAckrn/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUA/HQQEfhAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c48d4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = critics.copy()\n",
    "df['fresh'] = df.fresh == 'fresh'\n",
    "grp = df.groupby('critic')\n",
    "counts = grp.critic.count()  # number of reviews by each critic\n",
    "means = grp.fresh.mean()     # average freshness for each critic\n",
    "\n",
    "means[counts > 100].hist(bins=10, edgecolor='w', lw=1)\n",
    "plt.xlabel(\"Average Rating per critic\")\n",
    "plt.ylabel(\"Number of Critics\")\n",
    "plt.yticks([0, 2, 4, 6, 8, 10]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Exercise Set I</h3>\n",
    "<br/>\n",
    "<b>Exercise:</b> Look at the histogram above. Tell a story about the average ratings per critic. What shape does the distribution look like? What is interesting about the distribution? What might explain these interesting things?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram shapes can be influenced by the bin number. Here for example, a bin of 5 instead of 10 looks much closer to normal through slightly heavy to the right side, but one of 100 looks much less like a normal distribution. Taking this histogram at face value, we see that it looks mostly normal as well through still heavy on the right side. We draw from it a few interesting suppositions about critics. Critics like to give positive ratings but not too positive. You can see that movies rated at .5 or below occur much less often. A large number occur between .6 and .7 and much fewer get above .7 marks. Critics are writers writing to a very broad audience. An audience who might not continue to read thier reviews if they don't agree with the critic more often than not. Hence, critics seem to sparingly give out either high or low ratings. Now critics might hide or subdue thier true rating or preference of a movie but does their crititic reflect that? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Vector Space Model and a Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the diagrams here are snipped from [*Introduction to Information Retrieval* by Manning et. al.]( http://nlp.stanford.edu/IR-book/) which is a great resource on text processing. For additional information on text mining and natural language processing, see [*Foundations of Statistical Natural Language Processing* by Manning and Schutze](http://nlp.stanford.edu/fsnlp/).\n",
    "\n",
    "Also check out Python packages [`nltk`](http://www.nltk.org/), [`spaCy`](https://spacy.io/), [`pattern`](http://www.clips.ua.ac.be/pattern), and their associated resources. Also see [`word2vec`](https://en.wikipedia.org/wiki/Word2vec).\n",
    "\n",
    "Let us define the vector derived from document $d$ by $\\bar V(d)$. What does this mean? Each document is treated as a vector containing information about the words contained in it. Each vector has the same length and each entry \"slot\" in the vector contains some kind of data about the words that appear in the document such as presence/absence (1/0), count (an integer) or some other statistic. Each vector has the same length because each document shared the same vocabulary across the full collection of documents -- this collection is called a *corpus*.\n",
    "\n",
    "To define the vocabulary, we take a union of all words we have seen in all documents. We then just associate an array index with them. So \"hello\" may be at index 5 and \"world\" at index 99.\n",
    "\n",
    "Suppose we have the following corpus:\n",
    "\n",
    "`A Fox one day spied a beautiful bunch of ripe grapes hanging from a vine trained along the branches of a tree. The grapes seemed ready to burst with juice, and the Fox's mouth watered as he gazed longingly at them.`\n",
    "\n",
    "Suppose we treat each sentence as a document $d$. The vocabulary (often called the *lexicon*) is the following:\n",
    "\n",
    "$V = \\left\\{\\right.$ `a, along, and, as, at, beautiful, branches, bunch, burst, day, fox, fox's, from, gazed, grapes, hanging, he, juice, longingly, mouth, of, one, ready, ripe, seemed, spied, the, them, to, trained, tree, vine, watered, with`$\\left.\\right\\}$\n",
    "\n",
    "Then the document\n",
    "\n",
    "`A Fox one day spied a beautiful bunch of ripe grapes hanging from a vine trained along the branches of a tree`\n",
    "\n",
    "may be represented as the following sparse vector of word counts:\n",
    "\n",
    "$$\\bar V(d) = \\left( 4,1,0,0,0,1,1,1,0,1,1,0,1,0,1,1,0,0,0,0,2,1,0,1,0,0,1,0,0,0,1,1,0,0 \\right)$$\n",
    "\n",
    "or more succinctly as\n",
    "\n",
    "`[(0, 4), (1, 1), (5, 1), (6, 1), (7, 1), (9, 1), (10, 1), (12, 1), (14, 1), (15, 1), (20, 2), (21, 1), (23, 1),`\n",
    "`(26, 1), (30, 1), (31, 1)]`\n",
    "\n",
    "along with a dictionary\n",
    "\n",
    "``\n",
    "{\n",
    "    0: a, 1: along, 5: beautiful, 6: branches, 7: bunch, 9: day, 10: fox, 12: from, 14: grapes, \n",
    "    15: hanging, 19: mouth, 20: of, 21: one, 23: ripe, 24: seemed, 25: spied, 26: the, \n",
    "    30: tree, 31: vine, \n",
    "}\n",
    "``\n",
    "\n",
    "Then, a set of documents becomes, in the usual `sklearn` style, a sparse matrix with rows being sparse arrays representing documents and columns representing the features/words in the vocabulary.\n",
    "\n",
    "Notice that this representation loses the relative ordering of the terms in the document. That is \"cat ate rat\" and \"rat ate cat\" are the same. Thus, this representation is also known as the Bag-Of-Words representation.\n",
    "\n",
    "Here is another example, from the book quoted above, although the matrix is transposed here so that documents are columns:\n",
    "\n",
    "![novel terms](terms.png)\n",
    "\n",
    "Such a matrix is also catted a Term-Document Matrix. Here, the terms being indexed could be stemmed before indexing; for instance, `jealous` and `jealousy` after stemming are the same feature. One could also make use of other \"Natural Language Processing\" transformations in constructing the vocabulary. We could use Lemmatization, which reduces words to lemmas: work, working, worked would all reduce to work. We could remove \"stopwords\" from our vocabulary, such as common words like \"the\". We could look for particular parts of speech, such as adjectives. This is often done in Sentiment Analysis. And so on. It all depends on our application.\n",
    "\n",
    "From the book:\n",
    ">The standard way of quantifying the similarity between two documents $d_1$ and $d_2$  is to compute the cosine similarity of their vector representations $\\bar V(d_1)$ and $\\bar V(d_2)$:\n",
    "\n",
    "$$S_{12} = \\frac{\\bar V(d_1) \\cdot \\bar V(d_2)}{|\\bar V(d_1)| \\times |\\bar V(d_2)|}$$\n",
    "\n",
    "![Vector Space Model](vsm.png)\n",
    "\n",
    "\n",
    ">There is a far more compelling reason to represent documents as vectors: we can also view a query as a vector. Consider the query q = jealous gossip. This query turns into the unit vector $\\bar V(q)$ = (0, 0.707, 0.707) on the three coordinates below. \n",
    "\n",
    "![novel terms](terms2.png)\n",
    "\n",
    ">The key idea now: to assign to each document d a score equal to the dot product:\n",
    "\n",
    "$$\\bar V(q) \\cdot \\bar V(d)$$\n",
    "\n",
    "Then we can use this simple Vector Model as a Search engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text is\n",
      "Hop on pop\n",
      "Hop off pop\n",
      "Hop Hop hop\n",
      "\n",
      "Transformed text vector is \n",
      "[[1 0 1 1]\n",
      " [1 1 0 1]\n",
      " [3 0 0 0]]\n",
      "\n",
      "Words for each feature:\n",
      "[u'hop', u'off', u'on', u'pop']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = ['Hop on pop', 'Hop off pop', 'Hop Hop hop']\n",
    "print(\"Original text is\\n{}\".format('\\n'.join(text)))\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0)\n",
    "\n",
    "# call `fit` to build the vocabulary\n",
    "vectorizer.fit(text)\n",
    "\n",
    "# call `transform` to convert text to a bag of words\n",
    "x = vectorizer.transform(text)\n",
    "\n",
    "# CountVectorizer uses a sparse array to save memory, but it's easier in this assignment to \n",
    "# convert back to a \"normal\" numpy array\n",
    "x = x.toarray()\n",
    "\n",
    "print(\"\")\n",
    "print(\"Transformed text vector is \\n{}\".format(x))\n",
    "\n",
    "# `get_feature_names` tracks which word is associated with each column of the transformed x\n",
    "print(\"\")\n",
    "print(\"Words for each feature:\")\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "# Notice that the bag of words treatment doesn't preserve information about the *order* of words, \n",
    "# just their frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_xy(critics, vectorizer=None):\n",
    "    #Your code here    \n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(critics.quote)\n",
    "    X = X.tocsc()  # some versions of sklearn return COO format\n",
    "    y = (critics.fresh == 'fresh').values.astype(np.int)\n",
    "    return X, y\n",
    "X, y = make_xy(critics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Bayes' Theorem, we have that\n",
    "\n",
    "$$P(c \\vert f) = \\frac{P(c \\cap f)}{P(f)}$$\n",
    "\n",
    "where $c$ represents a *class* or category, and $f$ represents a feature vector, such as $\\bar V(d)$ as above. **We are computing the probability that a document (or whatever we are classifying) belongs to category *c* given the features in the document.** $P(f)$ is really just a normalization constant, so the literature usually writes Bayes' Theorem in context of Naive Bayes as\n",
    "\n",
    "$$P(c \\vert f) \\propto P(f \\vert c) P(c) $$\n",
    "\n",
    "$P(c)$ is called the *prior* and is simply the probability of seeing class $c$. But what is $P(f \\vert c)$? This is the probability that we see feature set $f$ given that this document is actually in class $c$. This is called the *likelihood* and comes from the data. One of the major assumptions of the Naive Bayes model is that the features are *conditionally independent* given the class. While the presence of a particular discriminative word may uniquely identify the document as being part of class $c$ and thus violate general feature independence, conditional independence means that the presence of that term is independent of all the other words that appear *within that class*. This is a very important distinction. Recall that if two events are independent, then:\n",
    "\n",
    "$$P(A \\cap B) = P(A) \\cdot P(B)$$\n",
    "\n",
    "Thus, conditional independence implies\n",
    "\n",
    "$$P(f \\vert c)  = \\prod_i P(f_i | c) $$\n",
    "\n",
    "where $f_i$ is an individual feature (a word in this example).\n",
    "\n",
    "To make a classification, we then choose the class $c$ such that $P(c \\vert f)$ is maximal.\n",
    "\n",
    "There is a small caveat when computing these probabilities. For [floating point underflow](http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html) we change the product into a sum by going into log space. This is called the LogSumExp trick. So:\n",
    "\n",
    "$$\\log P(f \\vert c)  = \\sum_i \\log P(f_i \\vert c) $$\n",
    "\n",
    "There is another caveat. What if we see a term that didn't exist in the training data? This means that $P(f_i \\vert c) = 0$ for that term, and thus $P(f \\vert c)  = \\prod_i P(f_i | c) = 0$, which doesn't help us at all. Instead of using zeros, we add a small negligible value called $\\alpha$ to each count. This is called Laplace Smoothing.\n",
    "\n",
    "$$P(f_i \\vert c) = \\frac{N_{ic}+\\alpha}{N_c + \\alpha N_i}$$\n",
    "\n",
    "where $N_{ic}$ is the number of times feature $i$ was seen in class $c$, $N_c$ is the number of times class $c$ was seen and $N_i$ is the number of times feature $i$ was seen globally. $\\alpha$ is sometimes called a regularization parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes and Other Likelihood Functions\n",
    "\n",
    "Since we are modeling word counts, we are using variation of Naive Bayes called Multinomial Naive Bayes. This is because the likelihood function actually takes the form of the multinomial distribution.\n",
    "\n",
    "$$P(f \\vert c) = \\frac{\\left( \\sum_i f_i \\right)!}{\\prod_i f_i!} \\prod_{f_i} P(f_i \\vert c)^{f_i} \\propto \\prod_{i} P(f_i \\vert c)$$\n",
    "\n",
    "where the nasty term out front is absorbed as a normalization constant such that probabilities sum to 1.\n",
    "\n",
    "There are many other variations of Naive Bayes, all which depend on what type of value $f_i$ takes. If $f_i$ is continuous, we may be able to use *Gaussian Naive Bayes*. First compute the mean and variance for each class $c$. Then the likelihood, $P(f \\vert c)$ is given as follows\n",
    "\n",
    "$$P(f_i = v \\vert c) = \\frac{1}{\\sqrt{2\\pi \\sigma^2_c}} e^{- \\frac{\\left( v - \\mu_c \\right)^2}{2 \\sigma^2_c}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Exercise Set II</h3>\n",
    "\n",
    "<p><b>Exercise:</b> Implement a simple Naive Bayes classifier:</p>\n",
    "\n",
    "<ol>\n",
    "<li> split the data set into a training and test set\n",
    "<li> Use `scikit-learn`'s `MultinomialNB()` classifier with default parameters.\n",
    "<li> train the classifier over the training set and test on the test set\n",
    "<li> print the accuracy scores for both the training and the test sets\n",
    "</ol>\n",
    "\n",
    "What do you notice? Is this a good classifier? If not, why not?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.92\n",
      "Accuracy on test data:     0.78\n"
     ]
    }
   ],
   "source": [
    "#your turn\n",
    "\n",
    "#import machine learning modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#transform data into vectors\n",
    "x,y=make_xy(critics)\n",
    "\n",
    "# split into training and test sets\n",
    "x_train, x_test, y_train, y_test= train_test_split(x,y, test_size=.3, random_state=42)\n",
    "\n",
    "#initiate the naive bayes classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit( x_train,y_train)\n",
    "\n",
    "#print the accuracy on the training data\n",
    "training_accuracy = clf.score(x_train, y_train)\n",
    "print(\"Accuracy on training data: {:0.2f}\".format(training_accuracy))\n",
    "\n",
    "#print the accuracy on the test data\n",
    "test_accuracy = clf.score(x_test, y_test)\n",
    "print(\"Accuracy on test data:     {:0.2f}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit on the training data is high compared to the test dats, therefore, I would suspect that the model is overfitting. However, the prediction on the test set is not bad. We do predict 78% correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking Hyperparameters for Naive Bayes and Text Maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to know what value to use for $\\alpha$, and we also need to know which words to include in the vocabulary. As mentioned earlier, some words are obvious stopwords. Other words appear so infrequently that they serve as noise, and other words in addition to stopwords appear so frequently that they may also serve as noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's find an appropriate value for `min_df` for the `CountVectorizer`. `min_df` can be either an integer or a float/decimal. If it is an integer, `min_df` represents the minimum number of documents a word must appear in for it to be included in the vocabulary. If it is a float, it represents the minimum *percentage* of documents a word must appear in to be included in the vocabulary. From the documentation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">min_df: When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Exercise Set III</h3>\n",
    "\n",
    "<p><b>Exercise:</b> Construct the cumulative distribution of document frequencies (df). The $x$-axis is a document count $x_i$ and the $y$-axis is the percentage of words that appear less than $x_i$ times. For example, at $x=5$, plot a point representing the percentage or number of words that appear in 5 or fewer documents.</p>\n",
    "\n",
    "<p><b>Exercise:</b> Look for the point at which the curve begins climbing steeply. This may be a good value for `min_df`. If we were interested in also picking `max_df`, we would likely pick the value where the curve starts to plateau. What value did you choose?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn the quote column into vectorized data\n",
    "df=vectorizer.fit_transform(critics.quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save vectors as an numpy array\n",
    "df_vectors=df.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  1, 10, ...,  3,  1,  1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sum columnwise along the array \n",
    "word_freq=df.toarray().sum(axis=0)\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 9552,\n",
       "         2: 3486,\n",
       "         3: 1916,\n",
       "         4: 1259,\n",
       "         5: 896,\n",
       "         6: 634,\n",
       "         7: 532,\n",
       "         8: 415,\n",
       "         9: 354,\n",
       "         10: 294,\n",
       "         11: 235,\n",
       "         12: 212,\n",
       "         13: 185,\n",
       "         14: 176,\n",
       "         15: 135,\n",
       "         16: 104,\n",
       "         17: 106,\n",
       "         18: 90,\n",
       "         19: 95,\n",
       "         20: 77,\n",
       "         21: 83,\n",
       "         22: 75,\n",
       "         23: 57,\n",
       "         24: 48,\n",
       "         25: 53,\n",
       "         26: 53,\n",
       "         27: 42,\n",
       "         28: 48,\n",
       "         29: 44,\n",
       "         30: 45,\n",
       "         31: 35,\n",
       "         32: 28,\n",
       "         33: 34,\n",
       "         34: 36,\n",
       "         35: 26,\n",
       "         36: 27,\n",
       "         37: 21,\n",
       "         38: 18,\n",
       "         39: 25,\n",
       "         40: 19,\n",
       "         41: 20,\n",
       "         42: 23,\n",
       "         43: 18,\n",
       "         44: 21,\n",
       "         45: 17,\n",
       "         46: 17,\n",
       "         47: 20,\n",
       "         48: 10,\n",
       "         49: 17,\n",
       "         50: 12,\n",
       "         51: 7,\n",
       "         52: 13,\n",
       "         53: 20,\n",
       "         54: 6,\n",
       "         55: 10,\n",
       "         56: 17,\n",
       "         57: 14,\n",
       "         58: 10,\n",
       "         59: 10,\n",
       "         60: 13,\n",
       "         61: 11,\n",
       "         62: 10,\n",
       "         63: 11,\n",
       "         64: 9,\n",
       "         65: 4,\n",
       "         66: 12,\n",
       "         67: 12,\n",
       "         68: 7,\n",
       "         69: 3,\n",
       "         70: 3,\n",
       "         71: 6,\n",
       "         72: 5,\n",
       "         73: 6,\n",
       "         74: 6,\n",
       "         75: 5,\n",
       "         76: 11,\n",
       "         77: 11,\n",
       "         78: 2,\n",
       "         79: 4,\n",
       "         80: 11,\n",
       "         81: 5,\n",
       "         82: 5,\n",
       "         83: 5,\n",
       "         84: 7,\n",
       "         85: 4,\n",
       "         86: 5,\n",
       "         87: 3,\n",
       "         88: 2,\n",
       "         89: 4,\n",
       "         90: 3,\n",
       "         91: 4,\n",
       "         92: 1,\n",
       "         93: 8,\n",
       "         94: 5,\n",
       "         95: 5,\n",
       "         96: 4,\n",
       "         97: 3,\n",
       "         98: 2,\n",
       "         99: 3,\n",
       "         100: 5,\n",
       "         101: 4,\n",
       "         102: 2,\n",
       "         103: 3,\n",
       "         104: 2,\n",
       "         105: 1,\n",
       "         106: 8,\n",
       "         107: 4,\n",
       "         108: 2,\n",
       "         110: 3,\n",
       "         111: 2,\n",
       "         112: 6,\n",
       "         113: 4,\n",
       "         116: 8,\n",
       "         117: 2,\n",
       "         118: 3,\n",
       "         119: 1,\n",
       "         121: 2,\n",
       "         122: 1,\n",
       "         123: 3,\n",
       "         124: 1,\n",
       "         126: 1,\n",
       "         127: 2,\n",
       "         128: 4,\n",
       "         130: 1,\n",
       "         131: 1,\n",
       "         133: 2,\n",
       "         134: 3,\n",
       "         135: 1,\n",
       "         137: 2,\n",
       "         138: 4,\n",
       "         140: 1,\n",
       "         141: 3,\n",
       "         142: 4,\n",
       "         144: 3,\n",
       "         145: 2,\n",
       "         146: 3,\n",
       "         147: 3,\n",
       "         149: 1,\n",
       "         150: 1,\n",
       "         151: 1,\n",
       "         153: 1,\n",
       "         154: 1,\n",
       "         156: 3,\n",
       "         157: 2,\n",
       "         158: 2,\n",
       "         159: 2,\n",
       "         160: 2,\n",
       "         161: 2,\n",
       "         162: 1,\n",
       "         166: 3,\n",
       "         169: 1,\n",
       "         170: 2,\n",
       "         172: 2,\n",
       "         175: 1,\n",
       "         176: 1,\n",
       "         177: 3,\n",
       "         178: 1,\n",
       "         179: 1,\n",
       "         182: 1,\n",
       "         183: 1,\n",
       "         184: 1,\n",
       "         186: 3,\n",
       "         188: 1,\n",
       "         189: 1,\n",
       "         191: 1,\n",
       "         192: 2,\n",
       "         195: 1,\n",
       "         196: 2,\n",
       "         198: 1,\n",
       "         199: 1,\n",
       "         200: 1,\n",
       "         201: 2,\n",
       "         202: 1,\n",
       "         205: 1,\n",
       "         207: 1,\n",
       "         208: 2,\n",
       "         209: 1,\n",
       "         210: 1,\n",
       "         212: 1,\n",
       "         213: 1,\n",
       "         214: 2,\n",
       "         219: 2,\n",
       "         221: 1,\n",
       "         222: 1,\n",
       "         223: 1,\n",
       "         225: 1,\n",
       "         226: 1,\n",
       "         227: 3,\n",
       "         231: 2,\n",
       "         232: 2,\n",
       "         233: 1,\n",
       "         234: 1,\n",
       "         236: 1,\n",
       "         237: 2,\n",
       "         239: 1,\n",
       "         242: 1,\n",
       "         244: 3,\n",
       "         248: 1,\n",
       "         249: 1,\n",
       "         252: 3,\n",
       "         254: 1,\n",
       "         256: 1,\n",
       "         257: 3,\n",
       "         258: 3,\n",
       "         260: 1,\n",
       "         261: 1,\n",
       "         263: 1,\n",
       "         264: 1,\n",
       "         266: 1,\n",
       "         271: 1,\n",
       "         272: 1,\n",
       "         273: 1,\n",
       "         274: 1,\n",
       "         276: 1,\n",
       "         278: 1,\n",
       "         279: 1,\n",
       "         282: 1,\n",
       "         284: 2,\n",
       "         287: 1,\n",
       "         288: 1,\n",
       "         290: 1,\n",
       "         293: 1,\n",
       "         295: 1,\n",
       "         296: 2,\n",
       "         301: 1,\n",
       "         305: 1,\n",
       "         306: 1,\n",
       "         320: 1,\n",
       "         322: 1,\n",
       "         324: 1,\n",
       "         330: 1,\n",
       "         336: 1,\n",
       "         341: 1,\n",
       "         343: 1,\n",
       "         344: 1,\n",
       "         354: 1,\n",
       "         363: 1,\n",
       "         364: 1,\n",
       "         367: 1,\n",
       "         369: 1,\n",
       "         370: 1,\n",
       "         383: 1,\n",
       "         386: 1,\n",
       "         387: 1,\n",
       "         388: 1,\n",
       "         396: 1,\n",
       "         399: 1,\n",
       "         413: 1,\n",
       "         415: 1,\n",
       "         417: 1,\n",
       "         422: 1,\n",
       "         433: 1,\n",
       "         434: 1,\n",
       "         438: 2,\n",
       "         439: 1,\n",
       "         443: 1,\n",
       "         462: 1,\n",
       "         469: 1,\n",
       "         472: 1,\n",
       "         478: 1,\n",
       "         496: 1,\n",
       "         504: 1,\n",
       "         507: 1,\n",
       "         531: 1,\n",
       "         540: 1,\n",
       "         545: 2,\n",
       "         572: 1,\n",
       "         591: 1,\n",
       "         599: 1,\n",
       "         615: 1,\n",
       "         644: 1,\n",
       "         657: 1,\n",
       "         663: 1,\n",
       "         688: 1,\n",
       "         689: 1,\n",
       "         691: 1,\n",
       "         702: 1,\n",
       "         703: 1,\n",
       "         711: 1,\n",
       "         744: 1,\n",
       "         790: 1,\n",
       "         821: 1,\n",
       "         864: 1,\n",
       "         875: 1,\n",
       "         887: 1,\n",
       "         993: 1,\n",
       "         1018: 1,\n",
       "         1024: 1,\n",
       "         1037: 1,\n",
       "         1069: 1,\n",
       "         1085: 1,\n",
       "         1121: 1,\n",
       "         1157: 1,\n",
       "         1237: 1,\n",
       "         1295: 1,\n",
       "         1301: 1,\n",
       "         1331: 1,\n",
       "         1390: 1,\n",
       "         1408: 2,\n",
       "         1836: 1,\n",
       "         1903: 1,\n",
       "         2148: 1,\n",
       "         2199: 1,\n",
       "         2267: 1,\n",
       "         2335: 1,\n",
       "         2411: 1,\n",
       "         2577: 1,\n",
       "         2858: 1,\n",
       "         3681: 1,\n",
       "         4252: 1,\n",
       "         5332: 1,\n",
       "         5974: 1,\n",
       "         6238: 1,\n",
       "         9778: 1,\n",
       "         9904: 1,\n",
       "         16805: 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import a counter \n",
    "from collections import Counter\n",
    "\n",
    "#count occurances that occur of words in documents i.e. how many words appear per document\n",
    "word_doc=Counter(word_freq)\n",
    "word_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22417"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(word_doc.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'maker', 9904), (u'routine', 2858), (u'long', 1836), (u'premise', 1157), (u'human', 1069), (u'situations', 1024), (u'contemporary', 1018), (u'drama', 396), (u'now', 330), (u'toward', 248), (u'later', 244), (u'intense', 242), (u'step', 214), (u'inner', 205), (u'during', 195), (u'formulaic', 177), (u'mrs', 172), (u'down', 170), (u'occasional', 144), (u'thrillers', 142), (u'inside', 140), (u'release', 123), (u'irresistible', 121), (u'frequently', 118), (u'far', 116), (u'itself', 112), (u'range', 110), (u'obvious', 103), (u'dumb', 99), (u'steven', 96), (u'minutes', 96), (u'terrible', 91), (u'missed', 90), (u'friends', 89), (u'douglas', 87), (u'll', 77), (u'ideas', 76), (u'elaborate', 69), (u'easy', 66), (u'doubt', 64), (u'otherwise', 63), (u'lets', 61), (u'worth', 57), (u'fresh', 57), (u'contrived', 56), (u'sort', 56), (u'others', 55), (u'gripping', 53), (u'presents', 53), (u'speed', 51)]\n"
     ]
    }
   ],
   "source": [
    "#lets look at the actual words\n",
    "#get words from vector\n",
    "words = list(vectorizer.get_feature_names())\n",
    "\n",
    "#save words with occurance frequency\n",
    "word_count = Counter(dict(zip(words, word_freq)))\n",
    "\n",
    "#print the 50 most common words\n",
    "print (word_count.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295413"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(word_count.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have done this with a for loop which we demonstrate below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dict to count word occurance in document(sentences)\n",
    "dict_words={i:0 for i in range(len(df_vectors[0]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over words in sentences\n",
    "for i in xrange(len(df_vectors[0])):\n",
    "    \n",
    "    #value holder for word occurances in sentences\n",
    "    y=0\n",
    "    \n",
    "    #loop over document/sentences counting word occurances\n",
    "    #sum up sentence/document one first word occurance with sentence/document two word one...\n",
    "    for j in xrange(len (df_vectors)):\n",
    "        y=y+df_vectors[j][i]\n",
    "        \n",
    "    #save word occurs in documents to dictionary\n",
    "    dict_words[i]=y\n",
    "    \n",
    "    #loop increments to next word to sum over sentences\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use counter to sum word occurance \n",
    "word_pert=Counter(dict_words.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 9552,\n",
       "         2: 3486,\n",
       "         3: 1916,\n",
       "         4: 1259,\n",
       "         5: 896,\n",
       "         6: 634,\n",
       "         7: 532,\n",
       "         8: 415,\n",
       "         9: 354,\n",
       "         10: 294,\n",
       "         11: 235,\n",
       "         12: 212,\n",
       "         13: 185,\n",
       "         14: 176,\n",
       "         15: 135,\n",
       "         16: 104,\n",
       "         17: 106,\n",
       "         18: 90,\n",
       "         19: 95,\n",
       "         20: 77,\n",
       "         21: 83,\n",
       "         22: 75,\n",
       "         23: 57,\n",
       "         24: 48,\n",
       "         25: 53,\n",
       "         26: 53,\n",
       "         27: 42,\n",
       "         28: 48,\n",
       "         29: 44,\n",
       "         30: 45,\n",
       "         31: 35,\n",
       "         32: 28,\n",
       "         33: 34,\n",
       "         34: 36,\n",
       "         35: 26,\n",
       "         36: 27,\n",
       "         37: 21,\n",
       "         38: 18,\n",
       "         39: 25,\n",
       "         40: 19,\n",
       "         41: 20,\n",
       "         42: 23,\n",
       "         43: 18,\n",
       "         44: 21,\n",
       "         45: 17,\n",
       "         46: 17,\n",
       "         47: 20,\n",
       "         48: 10,\n",
       "         49: 17,\n",
       "         50: 12,\n",
       "         51: 7,\n",
       "         52: 13,\n",
       "         53: 20,\n",
       "         54: 6,\n",
       "         55: 10,\n",
       "         56: 17,\n",
       "         57: 14,\n",
       "         58: 10,\n",
       "         59: 10,\n",
       "         60: 13,\n",
       "         61: 11,\n",
       "         62: 10,\n",
       "         63: 11,\n",
       "         64: 9,\n",
       "         65: 4,\n",
       "         66: 12,\n",
       "         67: 12,\n",
       "         68: 7,\n",
       "         69: 3,\n",
       "         70: 3,\n",
       "         71: 6,\n",
       "         72: 5,\n",
       "         73: 6,\n",
       "         74: 6,\n",
       "         75: 5,\n",
       "         76: 11,\n",
       "         77: 11,\n",
       "         78: 2,\n",
       "         79: 4,\n",
       "         80: 11,\n",
       "         81: 5,\n",
       "         82: 5,\n",
       "         83: 5,\n",
       "         84: 7,\n",
       "         85: 4,\n",
       "         86: 5,\n",
       "         87: 3,\n",
       "         88: 2,\n",
       "         89: 4,\n",
       "         90: 3,\n",
       "         91: 4,\n",
       "         92: 1,\n",
       "         93: 8,\n",
       "         94: 5,\n",
       "         95: 5,\n",
       "         96: 4,\n",
       "         97: 3,\n",
       "         98: 2,\n",
       "         99: 3,\n",
       "         100: 5,\n",
       "         101: 4,\n",
       "         102: 2,\n",
       "         103: 3,\n",
       "         104: 2,\n",
       "         105: 1,\n",
       "         106: 8,\n",
       "         107: 4,\n",
       "         108: 2,\n",
       "         110: 3,\n",
       "         111: 2,\n",
       "         112: 6,\n",
       "         113: 4,\n",
       "         116: 8,\n",
       "         117: 2,\n",
       "         118: 3,\n",
       "         119: 1,\n",
       "         121: 2,\n",
       "         122: 1,\n",
       "         123: 3,\n",
       "         124: 1,\n",
       "         126: 1,\n",
       "         127: 2,\n",
       "         128: 4,\n",
       "         130: 1,\n",
       "         131: 1,\n",
       "         133: 2,\n",
       "         134: 3,\n",
       "         135: 1,\n",
       "         137: 2,\n",
       "         138: 4,\n",
       "         140: 1,\n",
       "         141: 3,\n",
       "         142: 4,\n",
       "         144: 3,\n",
       "         145: 2,\n",
       "         146: 3,\n",
       "         147: 3,\n",
       "         149: 1,\n",
       "         150: 1,\n",
       "         151: 1,\n",
       "         153: 1,\n",
       "         154: 1,\n",
       "         156: 3,\n",
       "         157: 2,\n",
       "         158: 2,\n",
       "         159: 2,\n",
       "         160: 2,\n",
       "         161: 2,\n",
       "         162: 1,\n",
       "         166: 3,\n",
       "         169: 1,\n",
       "         170: 2,\n",
       "         172: 2,\n",
       "         175: 1,\n",
       "         176: 1,\n",
       "         177: 3,\n",
       "         178: 1,\n",
       "         179: 1,\n",
       "         182: 1,\n",
       "         183: 1,\n",
       "         184: 1,\n",
       "         186: 3,\n",
       "         188: 1,\n",
       "         189: 1,\n",
       "         191: 1,\n",
       "         192: 2,\n",
       "         195: 1,\n",
       "         196: 2,\n",
       "         198: 1,\n",
       "         199: 1,\n",
       "         200: 1,\n",
       "         201: 2,\n",
       "         202: 1,\n",
       "         205: 1,\n",
       "         207: 1,\n",
       "         208: 2,\n",
       "         209: 1,\n",
       "         210: 1,\n",
       "         212: 1,\n",
       "         213: 1,\n",
       "         214: 2,\n",
       "         219: 2,\n",
       "         221: 1,\n",
       "         222: 1,\n",
       "         223: 1,\n",
       "         225: 1,\n",
       "         226: 1,\n",
       "         227: 3,\n",
       "         231: 2,\n",
       "         232: 2,\n",
       "         233: 1,\n",
       "         234: 1,\n",
       "         236: 1,\n",
       "         237: 2,\n",
       "         239: 1,\n",
       "         242: 1,\n",
       "         244: 3,\n",
       "         248: 1,\n",
       "         249: 1,\n",
       "         252: 3,\n",
       "         254: 1,\n",
       "         256: 1,\n",
       "         257: 3,\n",
       "         258: 3,\n",
       "         260: 1,\n",
       "         261: 1,\n",
       "         263: 1,\n",
       "         264: 1,\n",
       "         266: 1,\n",
       "         271: 1,\n",
       "         272: 1,\n",
       "         273: 1,\n",
       "         274: 1,\n",
       "         276: 1,\n",
       "         278: 1,\n",
       "         279: 1,\n",
       "         282: 1,\n",
       "         284: 2,\n",
       "         287: 1,\n",
       "         288: 1,\n",
       "         290: 1,\n",
       "         293: 1,\n",
       "         295: 1,\n",
       "         296: 2,\n",
       "         301: 1,\n",
       "         305: 1,\n",
       "         306: 1,\n",
       "         320: 1,\n",
       "         322: 1,\n",
       "         324: 1,\n",
       "         330: 1,\n",
       "         336: 1,\n",
       "         341: 1,\n",
       "         343: 1,\n",
       "         344: 1,\n",
       "         354: 1,\n",
       "         363: 1,\n",
       "         364: 1,\n",
       "         367: 1,\n",
       "         369: 1,\n",
       "         370: 1,\n",
       "         383: 1,\n",
       "         386: 1,\n",
       "         387: 1,\n",
       "         388: 1,\n",
       "         396: 1,\n",
       "         399: 1,\n",
       "         413: 1,\n",
       "         415: 1,\n",
       "         417: 1,\n",
       "         422: 1,\n",
       "         433: 1,\n",
       "         434: 1,\n",
       "         438: 2,\n",
       "         439: 1,\n",
       "         443: 1,\n",
       "         462: 1,\n",
       "         469: 1,\n",
       "         472: 1,\n",
       "         478: 1,\n",
       "         496: 1,\n",
       "         504: 1,\n",
       "         507: 1,\n",
       "         531: 1,\n",
       "         540: 1,\n",
       "         545: 2,\n",
       "         572: 1,\n",
       "         591: 1,\n",
       "         599: 1,\n",
       "         615: 1,\n",
       "         644: 1,\n",
       "         657: 1,\n",
       "         663: 1,\n",
       "         688: 1,\n",
       "         689: 1,\n",
       "         691: 1,\n",
       "         702: 1,\n",
       "         703: 1,\n",
       "         711: 1,\n",
       "         744: 1,\n",
       "         790: 1,\n",
       "         821: 1,\n",
       "         864: 1,\n",
       "         875: 1,\n",
       "         887: 1,\n",
       "         993: 1,\n",
       "         1018: 1,\n",
       "         1024: 1,\n",
       "         1037: 1,\n",
       "         1069: 1,\n",
       "         1085: 1,\n",
       "         1121: 1,\n",
       "         1157: 1,\n",
       "         1237: 1,\n",
       "         1295: 1,\n",
       "         1301: 1,\n",
       "         1331: 1,\n",
       "         1390: 1,\n",
       "         1408: 2,\n",
       "         1836: 1,\n",
       "         1903: 1,\n",
       "         2148: 1,\n",
       "         2199: 1,\n",
       "         2267: 1,\n",
       "         2335: 1,\n",
       "         2411: 1,\n",
       "         2577: 1,\n",
       "         2858: 1,\n",
       "         3681: 1,\n",
       "         4252: 1,\n",
       "         5332: 1,\n",
       "         5974: 1,\n",
       "         6238: 1,\n",
       "         9778: 1,\n",
       "         9904: 1,\n",
       "         16805: 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#should be same as word_doc\n",
    "word_pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we want freq of words that appear in i documents (for x=5 that is words that appear in 5 documents)\n",
    "#empty variable for counting\n",
    "x=0\n",
    "\n",
    "#list of words per document for plotting later\n",
    "x_points=[]\n",
    "\n",
    "#list to hold word document counts and initialize with a zero for plotting later\n",
    "p_pert=[]\n",
    "\n",
    "#loop over counter and sum up occurances \n",
    "for i in word_doc.values():\n",
    "    #add previous words that appear less than xi to xi \n",
    "    x+=i\n",
    "    p=x\n",
    "    #save xi to list for plotting later\n",
    "    x_points.append(x)\n",
    "    #save cumulative count of word occurances less than or equal to xi for plotting\n",
    "    p_pert.append(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc0AAAE9CAYAAABp1zkEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+v9Cw33Zr/B4mQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d88f110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot CDF\n",
    "\n",
    "# get number of xi\n",
    "n = len(p_pert)\n",
    "\n",
    "fig, ax =plt.subplots()\n",
    "\n",
    "#x-axis points\n",
    "x=np.linspace(0,316,num=n)\n",
    "\n",
    "#plot CDF\n",
    "ax.plot(x,p_pert)\n",
    "\n",
    "# add labels\n",
    "_ = ax.set_xlabel('document count  Xi')\n",
    "_ = ax.set_ylabel('Counts')\n",
    "_ = ax.set_title('Cumulative Distribution Functions\\nNumber of words that appear less than  Xi times')\n",
    "\n",
    "#insert zoom in box (to better see min_df value)\n",
    "#where to plot insert\n",
    "inset_ax=fig.add_axes([0.55,.3,.35,.35])\n",
    "#plot insert\n",
    "inset_ax.plot(x,p_pert)\n",
    "#add labels to insert\n",
    "inset_ax.set_title('zoom in on left side')\n",
    "#outline insert\n",
    "inset_ax.set_frame_on('on')\n",
    "#designate zoom in region by x-axis\n",
    "inset_ax.set_xlim(0,40)\n",
    "plt.margins(0.02)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Look for the point at which the curve begins climbing steeply. This may be a good value for min_df. If we were interested in also picking max_df, we would likely pick the value where the curve starts to plateau. What value did you choose?\n",
    "\n",
    "\n",
    "Here we are looking at counts of words that appear in a document. X=1 then is all words that appear in exactly one document. In our data, words that appear in one document number 9552. We see that the data stabilizes after 20 documents for which words appear in. I, therefore, would recommend picking 20 as the min_df. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter $\\alpha$ is chosen to be a small value that simply avoids having zeros in the probability computations. This value can sometimes be chosen arbitrarily with domain expertise, but we will use K-fold cross validation. In K-fold cross-validation, we divide the data into $K$ non-overlapping parts. We train on $K-1$ of the folds and test on the remaining fold. We then iterate, so that each fold serves as the test fold exactly once. The function `cv_score` performs the K-fold cross-validation algorithm for us, but we need to pass a function that measures the performance of the algorithm on each fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def cv_score(clf, X, y, scorefunc):\n",
    "    result = 0.\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(X): # split data into train/test groups, 5 times\n",
    "        clf.fit(X[train], y[train]) # fit the classifier, passed is as clf.\n",
    "        result += scorefunc(clf, X[test], y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the log-likelihood as the score here in `scorefunc`. The higher the log-likelihood, the better. Indeed, what we do in `cv_score` above is to implement the cross-validation part of `GridSearchCV`.\n",
    "\n",
    "The custom scoring function `scorefunc` allows us to use different metrics depending on the decision risk we care about (precision, accuracy, profit etc.) directly on the validation set. You will often find people using `roc_auc`, precision, recall, or `F1-score` as the scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(clf, x, y):\n",
    "    prob = clf.predict_log_proba(x)\n",
    "    rotten = y == 0\n",
    "    fresh = ~rotten\n",
    "    return prob[rotten, 0].sum() + prob[fresh, 1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll cross-validate over the regularization parameter $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the train and test masks first, and then we can run the cross-validation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "_, itest = train_test_split(range(critics.shape[0]), train_size=0.7)\n",
    "mask = np.zeros(critics.shape[0], dtype=np.bool)\n",
    "mask[itest] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Exercise Set IV</h3>\n",
    "\n",
    "<p><b>Exercise:</b> What does using the function `log_likelihood` as the score mean? What are we trying to optimize for?</p>\n",
    "\n",
    "<p><b>Exercise:</b> Without writing any code, what do you think would happen if you choose a value of $\\alpha$ that is too high?</p>\n",
    "\n",
    "<p><b>Exercise:</b> Using the skeleton code below, find the best values of the parameter `alpha`, and use the value of `min_df` you chose in the previous exercise set. Use the `cv_score` function above with the `log_likelihood` function for scoring.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to optimize for the parameter selection. We want the maximum likelihood of data with respect to our parameters. A maximum likelihood selects the parameter so that the data is most likely to occur. Using the log_likelihood allows us to use the sum instead of the product. Two benefits of this is, it of keeping us from running out of floating point precision since the product gets very small quickly, and the computation is easier. \n",
    "\n",
    "If you choose an alpha that is to high, then your estimation/prediction is giving excess weight to items that did not occur in your data. You are in essense saying that what was not seen is much more likely to occur than what was seen. Your predictions will be much worse in the end. (Alpha is the smoothing term here)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score of -557.183660683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#the grid of parameters to search over\n",
    "alphas = [.1, 1, 5, 10, 50]\n",
    "best_min_df = 20 # YOUR TURN: put your value of min_df here.\n",
    "\n",
    "#Find the best value for alpha and min_df, and the best classifier\n",
    "best_alpha = None\n",
    "maxscore=-np.inf\n",
    "for alpha in alphas:        \n",
    "    vectorizer = CountVectorizer(min_df=best_min_df)       \n",
    "    Xthis, ythis = make_xy(critics, vectorizer)\n",
    "    Xtrainthis = Xthis[mask]\n",
    "    ytrainthis = ythis[mask]\n",
    "    # your turn\n",
    "    #initiate the naive bayes classifier\n",
    "    clf = MultinomialNB(alpha=alpha)\n",
    "    #call the score function to fit and evaluate\n",
    "    cross_score =  cv_score(clf,Xtrainthis,ytrainthis,log_likelihood)\n",
    "    \n",
    "    #save best score for comparsion in next loop\n",
    "    if cross_score>maxscore:\n",
    "        maxscore=cross_score\n",
    "        best_alpha=alpha\n",
    "#print best of the results        \n",
    "print(\"The best score of {}\".format(maxscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"alpha: {}\".format(best_alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Exercise Set V: Working with the Best Parameters</h3>\n",
    "\n",
    "<p><b>Exercise:</b> Using the best value of  `alpha` you just found, calculate the accuracy on the training and test sets. Is this classifier better? Why (not)?</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.791818\n",
      "Accuracy on test data:     0.717683\n"
     ]
    }
   ],
   "source": [
    "#use the best min_df in the vectorizer\n",
    "n_vectorizer = CountVectorizer(min_df=best_min_df)\n",
    "\n",
    "#split for test and training again\n",
    "X, y = make_xy(critics, n_vectorizer)\n",
    "xtrain=X[mask]\n",
    "ytrain=y[mask]\n",
    "xtest=X[~mask]\n",
    "ytest=y[~mask]\n",
    "\n",
    "#use the best alpha in the Naive Bayes\n",
    "clf = MultinomialNB(alpha=best_alpha).fit(xtrain, ytrain)\n",
    "\n",
    "#Print the accuracy on the test and training dataset\n",
    "nb_training_accuracy = clf.score(xtrain, ytrain)\n",
    "nb_test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(nb_training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(nb_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2190 2067]\n",
      " [1008 5627]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest, clf.predict(xtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, this is a better classifier. Previously, we got accuracy on training data at .92 and test data at .78. Here, we got accuracy on training data a .79 and test data at .72. This is better since we are not overfitting. Overfitting is the use of noise in the data to model the prediction. You can see this by the difference in test accuracy compared to training accuracy. The first case had a difference of .14 compared with .07 this time. The second model is using much less noise to make predictions thus its predictions can be considered to be more reliable even through the score is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the strongly predictive features?\n",
    "\n",
    "We use a neat trick to identify strongly predictive features (i.e. words). \n",
    "\n",
    "* first, create a data set such that each row has exactly one feature. This is represented by the identity matrix.\n",
    "* use the trained classifier to make predictions on this matrix\n",
    "* sort the rows by predicted probabilities, and pick the top and bottom $K$ rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good words\t     P(fresh | word)\n",
      "('           wonderful', '0.85')\n",
      "('         masterpiece', '0.85')\n",
      "('                epic', '0.85')\n",
      "('             delight', '0.84')\n",
      "('        entertaining', '0.84')\n",
      "('         intelligent', '0.84')\n",
      "('               today', '0.83')\n",
      "('           enjoyable', '0.83')\n",
      "('               witty', '0.83')\n",
      "('           excellent', '0.82')\n",
      "Bad words\t     P(fresh | word)\n",
      "('               bland', '0.30')\n",
      "('             tedious', '0.29')\n",
      "('                 nor', '0.29')\n",
      "('                dull', '0.29')\n",
      "('                lame', '0.28')\n",
      "('               awful', '0.26')\n",
      "('                flat', '0.25')\n",
      "('               video', '0.25')\n",
      "('           pointless', '0.25')\n",
      "('       unfortunately', '0.23')\n"
     ]
    }
   ],
   "source": [
    "words = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "x = np.eye(xtest.shape[1])\n",
    "probs = clf.predict_log_proba(x)[:, 0]\n",
    "ind = np.argsort(probs)\n",
    "\n",
    "good_words = words[ind[:10]]\n",
    "bad_words = words[ind[-10:]]\n",
    "\n",
    "good_prob = probs[ind[:10]]\n",
    "bad_prob = probs[ind[-10:]]\n",
    "\n",
    "print(\"Good words\\t     P(fresh | word)\")\n",
    "for w, p in zip(good_words, good_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))\n",
    "    \n",
    "print(\"Bad words\\t     P(fresh | word)\")\n",
    "for w, p in zip(bad_words, bad_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Exercise Set VI</h3>\n",
    "\n",
    "<p><b>Exercise:</b> Why does this method work? What does the probability for each row in the identity matrix represent</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of each row is the probility that the feature/word will be in the catagory fresh (recieve a good rating by the critic). This probability also tells us which features/words our classifer is using to determine if a critics review will be 'fresh'. It works because the Naive Bayes' pred_proba returns the probability for each word/feature set given the class/document, P(f|c), i.e. the likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above exercise is an example of *feature selection*. There are many other feature selection methods. A list of feature selection methods available in `sklearn` is [here](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection). The most common feature selection technique for text mining is the chi-squared $\\left( \\chi^2 \\right)$ [method](http://nlp.stanford.edu/IR-book/html/htmledition/feature-selectionchi2-feature-selection-1.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Errors\n",
    "\n",
    "We can see mis-predictions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mis-predicted Rotten quotes\n",
      "---------------------------\n",
      "It survives today only as an unusually pure example of a typical 50s art-film strategy: the attempt to make the most modern and most popular of art forms acceptable to the intelligentsia by forcing it into an arcane, antique mold.\n",
      "\n",
      "The thought that he may yet return for further adventures with his body and Lugosi's sconce fills us with mortal terror. That is the most fearful prospect which the picture manages to convey.\n",
      "\n",
      "Mr. Peckinpah's least interesting, least personal film in years, a hysterically elaborate, made-in-Yugoslavia war spectacle, the work of international financiers and a multinational cast.\n",
      "\n",
      "Lauded as a witty moral fable with a revelatory performance from its star, this romantic comedy is in fact meretricious, manipulative and reactionary.\n",
      "\n",
      "Walken is one of the few undeniably charismatic male villains of recent years; he can generate a snakelike charm that makes his worst characters the most memorable, and here he operates on pure style.\n",
      "\n",
      "Mis-predicted Fresh quotes\n",
      "--------------------------\n",
      "Though it's a good half hour too long, this overblown 1993 spin-off of the 60s TV show otherwise adds up to a pretty good suspense thriller.\n",
      "\n",
      "There are some gaps in the movie's reality, and some O. Henry-like contrivances, but the masterful trick Boy A plays on viewers is to get them to care before giving them reasons not to.\n",
      "\n",
      "There's too much talent and too strong a story to mess it up. There was potential for more here, but this incarnation is nothing to be ashamed of, and some of the actors answer the bell.\n",
      "\n",
      "There's a lot more to Nowhere in Africa -- too much, actually ... Yet even if the movie has at least one act too many, the question that runs through it -- of whether belonging to a place is a matter of time or of will -- remains consistent.\n",
      "\n",
      "The three leads inhabit their roles in the way only unknown actors can. They really seem to become the characters they're playing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, y = make_xy(critics, vectorizer)\n",
    "\n",
    "prob = clf.predict_proba(x)[:, 0]\n",
    "predict = clf.predict(x)\n",
    "\n",
    "bad_rotten = np.argsort(prob[y == 0])[:5]\n",
    "bad_fresh = np.argsort(prob[y == 1])[-5:]\n",
    "\n",
    "print(\"Mis-predicted Rotten quotes\")\n",
    "print('---------------------------')\n",
    "for row in bad_rotten:\n",
    "    print(critics[y == 0].quote.iloc[row])\n",
    "    print(\"\")\n",
    "\n",
    "print(\"Mis-predicted Fresh quotes\")\n",
    "print('--------------------------')\n",
    "for row in bad_fresh:\n",
    "    print(critics[y == 1].quote.iloc[row])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Exercise Set VII: Predicting the Freshness for a New Review</h3>\n",
    "<br/>\n",
    "<div>\n",
    "<b>Exercise:</b>\n",
    "<ul>\n",
    "<li> Using your best trained classifier, predict the freshness of the following sentence: *'This movie is not remarkable, touching, or superb in any way'*\n",
    "<li> Is the result what you'd expect? Why (not)?\n",
    "</ul>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text=['This movie is not remarkable, touching, or superb in any way']\n",
    "type(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change text into vector\n",
    "new_text=vectorizer.transform(new_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#make prediciton on new set\n",
    "print(clf.predict(new_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It predicts that this sentence would be classified as 'fresh'. This would be a false positive as we can tell from reading the sentence. It is not too surprising that the classifier gets this wrong. The classifier here is only looking at words that have a high probability of being in the class 'fresh'. This sentence contains at three words we would expect to be highly associated with the 'fresh' class, hence, it predicts it is. The 'not' here does not alert the classifer that these three positive words should be negatively associated resulting in a misclassification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: TF-IDF Weighting for Term Importance\n",
    "\n",
    "TF-IDF stands for \n",
    "\n",
    "`Term-Frequency X Inverse Document Frequency`.\n",
    "\n",
    "In the standard `CountVectorizer` model above, we used just the term frequency in a document of words in our vocabulary. In TF-IDF, we weight this term frequency by the inverse of its popularity in all documents. For example, if the word \"movie\" showed up in all the documents, it would not have much predictive value. It could actually be considered a stopword. By weighing its counts by 1 divided by its overall frequency, we downweight it. We can then use this TF-IDF weighted features as inputs to any classifier. **TF-IDF is essentially a measure of term importance, and of how discriminative a word is in a corpus.** There are a variety of nuances involved in computing TF-IDF, mainly involving where to add the smoothing term to avoid division by 0, or log of 0 errors. The formula for TF-IDF in `scikit-learn` differs from that of most textbooks: \n",
    "\n",
    "$$\\mbox{TF-IDF}(t, d) = \\mbox{TF}(t, d)\\times \\mbox{IDF}(t) = n_{td} \\log{\\left( \\frac{\\vert D \\vert}{\\vert d : t \\in d \\vert} + 1 \\right)}$$\n",
    "\n",
    "where $n_{td}$ is the number of times term $t$ occurs in document $d$, $\\vert D \\vert$ is the number of documents, and $\\vert d : t \\in d \\vert$ is the number of documents that contain $t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/dev/modules/feature_extraction.html#text-feature-extraction\n",
    "# http://scikit-learn.org/dev/modules/classes.html#text-feature-extraction-ref\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfvectorizer = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "Xtfidf=tfidfvectorizer.fit_transform(critics.quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Exercise Set VIII: Enrichment</h3>\n",
    "\n",
    "<p>\n",
    "There are several additional things we could try. Try some of these as exercises:\n",
    "<ol>\n",
    "<li> Build a Naive Bayes model where the features are n-grams instead of words. N-grams are phrases containing n words next to each other: a bigram contains 2 words, a trigram contains 3 words, and 6-gram contains 6 words. This is useful because \"not good\" and \"so good\" mean very different things. On the other hand, as n increases, the model does not scale well since the feature set becomes more sparse.\n",
    "<li> Try a model besides Naive Bayes, one that would allow for interactions between words -- for example, a Random Forest classifier.\n",
    "<li> Try adding supplemental features -- information about genre, director, cast, etc.\n",
    "<li> Use word2vec or [Latent Dirichlet Allocation](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) to group words into topics and use those topics for prediction.\n",
    "<li> Use TF-IDF weighting instead of word counts.\n",
    "</ol>\n",
    "</p>\n",
    "\n",
    "<b>Exercise:</b> Try a few of these ideas to improve the model (or any other ideas of your own). Implement here and report on the result.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by building a Naive Bayes model that considers only 2 n-grams instead of words that is we will only look at pairs of words that appear next to each other. The hope is that this model will be able to distinguish terms like \"not bad\" and register it as good when considering more than one word.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  28   31   36   40  206   30   22   20   20   29   28   24   20   45   32\n",
      "   21   56   76   29  256   27   21   43   27   23   22   27   22   29   24\n",
      "   29   20   21   32   34   54   41   22   21   33   33   20   46   22   37\n",
      "   32   47   24   95   60   24  172   75   59   44   29   56   25   37   42\n",
      "   32   22   63  661   25   51   47   24   27   20   24   34   21   26   26\n",
      "   40   27   31   34   30   22   23   26   25   42   34   29   96   40   29\n",
      "   82  179   50   54   26  279   27  113   34   21   30   60   96   22  254\n",
      "   52   41   21   28   41   22   24   21   87   22   60   43   24   29   21\n",
      "   20   24   26   21   54   46   34   34   24   22   23   21   33   38   47\n",
      "   20   51  368   28   21   20   81   34  247   59   25   62   22   31   25\n",
      "   23   27  262  106   23   25   21   63   38   28   27   26   34   45   28\n",
      "   21   40   32   21   33   32   48   43   36   26   28   23   25   29   36\n",
      "   22   21   52   22   22   26   25   29   28   31   21   38   33   35   43\n",
      "   25  128   31   21   57   22   35   58   25   64   24   51   40   34   53\n",
      "   31   21   23   23   21   36   39   37   31   28   28   22   43   36  277\n",
      "   24   65  163   38   46   23   28   28   24   37   95   30   26   33   72\n",
      "  381   27   35   20   30  261   89   23   24   72   28   51   27   29   22\n",
      "   21   20  102   22   36   24  106   23   39   45   27   28   89   26  157\n",
      "   22   37   62   24   26   41   51   25   22   50   32   28   24   21   50\n",
      "   24   27   50   55   26   72   32   22   88   23  170   22   38   58   25\n",
      "   23   79   21   28  192   21   28   20   27   23   21   26   21   22 1010\n",
      "   33  181  105   25   23   52   24   23   26   27  135   52   35   34  172\n",
      "  107   29   22   21   54   21   70   43   33   32   49   28   67   43   24\n",
      "   41  170   28   21  151   29   20  153   31   59   21  149  419   73   49\n",
      "   32   27   24   80   62   56   29   40   20   33   35   25   60   74   21\n",
      "   22   26   54  131   33  554   28   51   21   20   42   46   37   26   42\n",
      "  121   21   33   22   26   48   30  109   35   21   68   33   40   22   56\n",
      "   21   33  130   20   27   23   43   28   25   23  245   22   42   31   37\n",
      "   39   26   20   31   30   92   33   43   35   25   64   21   21  112   33\n",
      "   30   54   20   24   48   53   50   42   51   31   20   67   39  151   30\n",
      "   56   25   39   74   28   30   21   36   27   38  225   20  130   72   41\n",
      "   46   40   24   61   43  226   29   53  172   31   45   29   36   48   98\n",
      "   26   21   21   23   23   24   20   26   34   22   37   36   32   53   30\n",
      "   29   85   25   40   85   20   22   29   27   90   28  103   28   27   21\n",
      "   20   62   38   32   25   27   23  175   33   35   24   34   74  253   28\n",
      "   22  110   38   38   21   20   20   21   24 2094   54   55   31  151   93\n",
      "   37   26   46   21   54   59   23   58   31  393   22   21   32   24  520\n",
      "   28   22   30   23   36  193   31   64   84   56   32   22   20   30   28\n",
      "   22   21   25   33   93   25   43   25   35   43   33   22   44   21   23\n",
      "   21   24   51   72   23   57   48   24   33   24   25   22   46   96   21\n",
      "  129   52   36   24   56   34   23   22   45   22   41   82  103   27   89\n",
      "  112   21   25   21   43   47   60   44   24   23   22   28   21   23   20\n",
      "   35   26   31   23   54   21   30  134   22   32   23   45   37   25   29\n",
      "   21   41   23   48  143  215   26   21   61   20   22   32  209   26   33\n",
      "   41   29   43   41   25   60   51   56   53   39   28  103  260   65   32\n",
      "   27   38   21  118   23   22   27   75  134   30   20  868   49   37   25\n",
      "  178   24   30   43   50   28   41   34   26   27  124   57   26   26   55\n",
      "   47  350  708   50   64   37   39   34   54   78   34   23   26   63   99\n",
      "   93   40   31   25   51   37   58   62   26  141  113   44   79   31   39\n",
      "   33   24  201   31   23   23   68   30   45   40   51   42   28  157   66\n",
      "   22   89   33  100   24  129  138   20   55   26   38   32   30   38   72\n",
      "   20   21   21   20  167  433  170   78   34   20   64   48   47   32   21\n",
      "   75   31   32   36  582   22   20   40   24   33   94   22   22   37   71\n",
      "   39   39   88   36   26   88   64   42   32   34  199   24   20   23   23\n",
      "   53  111   55   21  622   28   40   82   31   21   20   47   66   22   24\n",
      "   31   47   32   38   21   24   23   32   40  100   54   45   35   25   21\n",
      "   27   49   63   51   30   24   28   28   80   39   22   27   21   33   36\n",
      "   22   31   23   33   25   47   24   30   76   25   41   74   34   51   20\n",
      "   21   20   22   99   57   21   33   33   71   20   37   22   46   20   24\n",
      "   27   27   30   63   29   27   76   20   54   36   73   27   39   45  353\n",
      "   36   31   25   41   35   24   21   93   43   63   24   33  105   41   38\n",
      "   49   21   64   39   33  111   22   75   26   21]\n"
     ]
    }
   ],
   "source": [
    "#make an instance of the COuntVectorizer that considers only 2 words for the bag of words\n",
    "vec = CountVectorizer(analyzer ='word',min_df=best_min_df, ngram_range=(2, 2))\n",
    "\n",
    "#fit and transform the vectorizer to the data\n",
    "ng=vec.fit_transform(critics.quote)\n",
    "\n",
    "#save as a numpy array\n",
    "ng_vectors=ng.toarray()\n",
    "\n",
    "#sum over the columns (word pairs) of the array\n",
    "ng_word_freq=ng.toarray().sum(axis=0)\n",
    "\n",
    "print(ng_word_freq)\n",
    "\n",
    "#count the number of word pairs occurances per document\n",
    "ng_word_doc=Counter(ng_word_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'of the', 2094), (u'in the', 1010), (u'the film', 868), (u'the movie', 708), (u'and the', 661), (u'to the', 622), (u'to be', 582), (u'it is', 554), (u'one of', 520), (u'this is', 433), (u'is the', 419), (u'on the', 393), (u'for the', 381), (u'but it', 368), (u'with the', 353), (u'the most', 350), (u'as the', 279), (u'film is', 277), (u'by the', 262), (u'from the', 261), (u'the best', 260), (u'all the', 256), (u'at the', 254), (u'of its', 253), (u'but the', 247), (u'kind of', 245), (u'movie is', 226), (u'more than', 225), (u'that it', 215), (u'that the', 209), (u'about the', 206), (u'the story', 201), (u'to make', 199), (u'out of', 193), (u'in its', 192), (u'in this', 181), (u'as it', 179), (u'the first', 178), (u'of his', 175), (u'and it', 172), (u'movie that', 172), (u'is an', 172), (u'is not', 170), (u'if you', 170), (u'this movie', 170), (u'this film', 167), (u'film that', 163), (u'have been', 157), (u'the way', 157), (u'is so', 153)]\n"
     ]
    }
   ],
   "source": [
    "#lets see what the word pairs look like\n",
    "#get the word pairs actual pharses\n",
    "ng_words = list(vec.get_feature_names())\n",
    "\n",
    "#zip the words to their respective count and print\n",
    "ng_word_count = Counter(dict(zip(ng_words, ng_word_freq)))\n",
    "print (ng_word_count.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the min_df: 20 and the alpha: 5 from before with 2 n-grams we get:\n",
      "Accuracy on training data: 0.700792\n",
      "Accuracy on test data:     0.638542\n"
     ]
    }
   ],
   "source": [
    "#lets see how the 2 n-gram vector works with the Naive Bayes model\n",
    "\n",
    "#print best of the results        \n",
    "print(\"Using the min_df: {} and the alpha: {} from before with 2 n-grams we get:\".format(best_min_df,best_alpha))\n",
    "\n",
    "#split the data into training and test sets\n",
    "x_ng, y_ng = make_xy(critics, vec)\n",
    "\n",
    "xtrainng=x_ng[mask]\n",
    "ytrainng=y_ng[mask]\n",
    "xtestng=x_ng[~mask]\n",
    "ytestng=y_ng[~mask]\n",
    "\n",
    "#create a new Multinomial Naive Bayes Classifier instance and fit it on the training set\n",
    "ngclf = MultinomialNB(alpha= best_alpha).fit(xtrainng, ytrainng)\n",
    "\n",
    "#Print the accuracy on the test and training dataset\n",
    "ngtraining_accuracy = ngclf.score(xtrainng, ytrainng)\n",
    "ngtest_accuracy = ngclf.score(xtestng, ytestng)\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(ngtraining_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(ngtest_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like with 2 n-grams lowered the noise but predicts worse overall. How should we that this? We miss more predictions but of the correct answers we can be more confident that are model is correct. How did we do on looking word flips? For example, \"This movie is not bad.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1]), 'fresh: 2-gram')\n",
      "[[ 0.4765044  0.5234956]]\n",
      "(array([0]), 'fresh: word only')\n",
      "[[ 0.69959366  0.30040634]]\n"
     ]
    }
   ],
   "source": [
    "#test review to predict\n",
    "new_text=['This movie is not bad']\n",
    "\n",
    "#2-gram prediction\n",
    "new_vec=vec.transform(new_text)\n",
    "print(ngclf.predict(new_vec),'fresh: 2-gram')\n",
    "print(ngclf.predict_proba(new_vec))\n",
    "\n",
    "#only singel word prediction\n",
    "new_vec=vectorizer.transform(new_text)\n",
    "print(clf.predict(new_vec),'fresh: word only')\n",
    "print(clf.predict_proba(new_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model, while not predicting better overall, does do a better job handling the flip pharses when calculating probability. We see that it does at least catch this flip pharse correctly where the original model did not. This is why we wanted to look a the 2 n-gram model. However, if you are just wanting to get prediction correct the first model will over time do better but will miss most examples like this.\n",
    "\n",
    "Now lets look at an example of the TF-IDF model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the min_df: 20 and the alpha: 5 from before with TF-IDF we get:\n",
      "Accuracy on training data: 0.672949\n",
      "Accuracy on test data:     0.643867\n"
     ]
    }
   ],
   "source": [
    "#print parameters of the results        \n",
    "print(\"Using the min_df: {} and the alpha: {} from before with TF-IDF we get:\".format(best_min_df,best_alpha))\n",
    "\n",
    "#create an instance of the vectorizer\n",
    "tfidfvectorizer = TfidfVectorizer(min_df=best_min_df)\n",
    "\n",
    "#split the data into test and training data again\n",
    "x_tfid, y_tfid = make_xy(critics, tfidfvectorizer)\n",
    "xtraintfid=x_tfid[mask]\n",
    "ytraintfid=y_tfid[mask]\n",
    "xtesttfid=x_tfid[~mask]\n",
    "ytesttfid=y_tfid[~mask]\n",
    "\n",
    "#create a new instance of the Multinomial Naive Bayes Classifier and fit it on the trianing data\n",
    "tfid_clf = MultinomialNB(alpha=best_alpha).fit(xtraintfid, ytraintfid)\n",
    "\n",
    "#Print the accuracy on the test and training dataset\n",
    "tf_training_accuracy = tfid_clf.score(xtraintfid, ytraintfid)\n",
    "tf_test_accuracy = tfid_clf.score(xtesttfid, ytesttfid)\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(tf_training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(tf_test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that the TF-IDF does reduce the noise between the training and test set results but does even worse at predicting. We could improve this by removing english stop words in a hope to do better. \n",
    "\n",
    "Next we look at a Random Forest. First lets try it straight out of the box to see how it does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.99\n",
      "Accuracy on test data: 0.68\n"
     ]
    }
   ],
   "source": [
    "#print best of the results        \n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Do a standard vectorization of the data\n",
    "x,y=make_xy(critics)\n",
    "\n",
    "# split into training and test sets\n",
    "x_train, x_test, y_train, y_test= train_test_split(x,y, test_size=.3, random_state=42)\n",
    "\n",
    "#create an Random Forest Classifier instance\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Fit the model on the trainng data.\n",
    "rf.fit( x_train,y_train)\n",
    "\n",
    "#print the accuracy on the training data\n",
    "training_accuracy = rf.score(x_train, y_train)\n",
    "print(\"Accuracy on training data: {:0.2f}\".format(training_accuracy))\n",
    "\n",
    "ftest_accuracy = rf.score(x_test, y_test)\n",
    "print(\"Accuracy on test data: {:0.2f}\".format(ftest_accuracy))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has done quite badly. We clearly are overfitting. We will need to fix this. First we need to refine the cv_score function to look at accuracy, since that is the final score we have been comparing models too. We then will adjust the depth of trees in the forest to prevent fitting to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to use in the for loop to quickly get accuracy score\n",
    "def accy_score(clf, x, y):\n",
    "    score = clf.score(x,y)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:00<00:00, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.78817733990147787, 30)\n",
      "Accuracy on training data: 0.788177\n",
      "Accuracy on test data:     0.649835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#new instance of the vectorizer with the same min_df \n",
    "vec = CountVectorizer(min_df=best_min_df)\n",
    "\n",
    "#split the vectorized data again into test and training\n",
    "x_rf, y_rf = make_xy(critics, vec)\n",
    "\n",
    "xtrainrf=x_rf[mask]\n",
    "ytrainrf=y_rf[mask]\n",
    "xtestrf=x_rf[~mask]\n",
    "ytestrf=y_rf[~mask]\n",
    "\n",
    "#create an instance of the Random Forest Classifier to use in the for loop\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "#variable to capture best score of loops sequences\n",
    "best_score=0\n",
    "\n",
    "#depth of trees to try\n",
    "max_depth=[1,5,10,30]\n",
    "\n",
    "#variable to catch best depth\n",
    "best_depth=0\n",
    "\n",
    "#loop over depths using progress bar and capturing the best score and best depth\n",
    "for i in tqdm(max_depth):\n",
    "    rf=RandomForestClassifier(max_depth=i).fit(xtrainrf, ytrainrf)\n",
    "    rf.fit(xtrain,ytrainrf)    \n",
    "    score=accy_score(rf, xtrainrf, ytrainrf)\n",
    "    \n",
    "    #compare loop score and variables to best and capture if needed\n",
    "    if score>best_score:\n",
    "        best_score=score\n",
    "        best_depth=i\n",
    "\n",
    "#Print the accuracy on the test and training dataset\n",
    "rftraining_accuracy = rf.score(xtrainrf, ytrainrf)\n",
    "rftest_accuracy = rf.score(xtestrf, ytestrf)\n",
    "print(best_score,best_depth)\n",
    "print(\"Accuracy on training data: {:2f}\".format(rftraining_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(rftest_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that limiting the tree depth has helped with overfitting the model. The random forest doesn't do as well as the naive bayes model. The prediction rate on the test set is much worse at .65 compared to .71 for the Naive Bayes model with best parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAErCAYAAACLlhe2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10da930d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model={'RF':rftest_accuracy,'TF_IDF':tf_test_accuracy,'2_ngram':ngtest_accuracy, 'MNB':nb_test_accuracy}\n",
    "\n",
    "plt.bar(plot_model.keys(), plot_model.values())\n",
    "plt.tight_layout()\n",
    "\n",
    "#add label and title\n",
    "plt.title(\"Comparison of the different models\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Accuracy Score on Test Set\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the tuning we did with the Naive Bayes outperformed all the other models in prediction on the test set. We might be able to do better with one of the other models if we invested as much as we did with the Navie Bayes model. However, the Naive Bayes was fairly easy to tune and able to do a decent job predicting the result of the critic rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
